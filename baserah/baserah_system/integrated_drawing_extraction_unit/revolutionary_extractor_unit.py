#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Revolutionary Extractor Unit for Basira System
ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠØ© - Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø©

Extraction component that uses shape_equation_extractor_final_v3 for reverse engineering.
Ù…ÙƒÙˆÙ† Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø°ÙŠ ÙŠØ³ØªØ®Ø¯Ù… shape_equation_extractor_final_v3 Ù„Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¹ÙƒØ³ÙŠØ©.

Author: Basira System Development Team
Created by: Basil Yahya Abdullah - Iraq/Mosul
Version: 1.0.0
"""

import numpy as np
import math
import sys
from typing import Dict, Any

# Add current directory to path
sys.path.insert(0, '.')

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
try:
    from shape_equation_extractor_final_v3 import ShapeEquationExtractor
    EXTRACTOR_UNIT_AVAILABLE = True
    print("âœ… ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø· Ù…ØªØ§Ø­Ø©: shape_equation_extractor_final_v3")
except ImportError as e:
    EXTRACTOR_UNIT_AVAILABLE = False
    print(f"âš ï¸ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø· ØºÙŠØ± Ù…ØªØ§Ø­Ø©: {e}")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âš ï¸ OpenCV ØºÙŠØ± Ù…ØªØ§Ø­ - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¨Ø³Ø·Ø©")


class RevolutionaryExtractorUnit:
    """ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠØ©"""

    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠØ©"""
        self.extractor_available = EXTRACTOR_UNIT_AVAILABLE

        if self.extractor_available:
            try:
                self.shape_extractor = ShapeEquationExtractor()
                print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠØ©")
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·: {e}")
                self.extractor_available = False

        if not self.extractor_available:
            print("âš ï¸ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ù…Ø¨Ø³Ø·Ø©")

    def extract_equation_from_image(self, image: np.ndarray) -> Dict[str, Any]:
        """Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©"""

        if self.extractor_available:
            try:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
                result = self._use_original_extractor(image)
                return {
                    "success": True,
                    "method": "shape_equation_extractor_final_v3",
                    "result": result,
                    "message": "ØªÙ… Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©"
                }
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: {e}")
                return self._use_fallback_extraction(image)
        else:
            return self._use_fallback_extraction(image)

    def _use_original_extractor(self, image: np.ndarray) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø£ØµÙ„ÙŠØ©"""
        # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        return self.shape_extractor.extract_shape_equation(image)

    def _use_fallback_extraction(self, image: np.ndarray) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ø¨Ø³Ø·"""
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ØµØ§Ø¦Øµ Ù…Ø¨Ø³Ø·Ø©
        features = self._extract_simple_features(image)

        return {
            "success": True,
            "method": "fallback_simple_extraction",
            "message": "ØªÙ… Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø¨Ø³Ø·Ø©",
            "result": {
                "equation_params": features["equation_params"],
                "geometric_features": features["geometric_features"],
                "color_properties": features["color_properties"],
                "position_info": features["position_info"],
                "confidence": 0.7
            }
        }

    def _extract_simple_features(self, image: np.ndarray) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ØµØ§Ø¦Øµ Ù…Ø¨Ø³Ø·Ø©"""
        # ØªØ­ÙˆÙŠÙ„ Ù„Ø±Ù…Ø§Ø¯ÙŠ
        if len(image.shape) == 3:
            gray = np.mean(image, axis=2).astype(np.uint8)
        else:
            gray = image

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        area = np.sum(gray > 50)
        height, width = gray.shape

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†
        dominant_color = self._extract_dominant_color(image)

        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø±ÙƒØ² Ø§Ù„ÙƒØªÙ„Ø©
        center_x, center_y = self._find_center_of_mass(gray)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        geometric_features = self._calculate_advanced_geometry(gray)

        # ØªÙ‚Ø¯ÙŠØ± Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©
        equation_params = self._estimate_equation_parameters(gray, geometric_features)

        return {
            "equation_params": equation_params,
            "geometric_features": geometric_features,
            "color_properties": {
                "dominant_color": dominant_color,
                "secondary_colors": self._extract_secondary_colors(image),
                "brightness": np.mean(image) / 255.0 if len(image.shape) == 3 else np.mean(gray) / 255.0,
                "saturation": self._calculate_saturation(image),
                "hue_range": self._calculate_hue_range(image)
            },
            "position_info": {
                "center_x": center_x,
                "center_y": center_y,
                "orientation": self._calculate_orientation(gray),
                "bounding_box": self._find_bounding_box(gray)
            }
        }

    def _extract_dominant_color(self, image: np.ndarray) -> list:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†"""
        if len(image.shape) == 3:
            pixels = image.reshape(-1, 3)
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡
            non_black = pixels[np.sum(pixels, axis=1) > 30]

            if len(non_black) > 0:
                return np.mean(non_black, axis=0).astype(int).tolist()
            else:
                return [128, 128, 128]
        else:
            return [128, 128, 128]

    def _extract_secondary_colors(self, image: np.ndarray) -> list:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©"""
        if len(image.shape) == 3:
            pixels = image.reshape(-1, 3)
            non_black = pixels[np.sum(pixels, axis=1) > 30]

            if len(non_black) > 100:
                # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… k-means Ù…Ø¨Ø³Ø·
                unique_colors = []
                for i in range(0, len(non_black), len(non_black)//5):
                    color = non_black[i].tolist()
                    if not any(np.linalg.norm(np.array(color) - np.array(uc)) < 50 for uc in unique_colors):
                        unique_colors.append(color)
                        if len(unique_colors) >= 3:
                            break

                return unique_colors[:3]

        return []

    def _find_center_of_mass(self, gray: np.ndarray) -> tuple:
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø±ÙƒØ² Ø§Ù„ÙƒØªÙ„Ø©"""
        y_indices, x_indices = np.where(gray > 50)

        if len(x_indices) > 0 and len(y_indices) > 0:
            center_x = np.mean(x_indices) / gray.shape[1]
            center_y = np.mean(y_indices) / gray.shape[0]
        else:
            center_x = 0.5
            center_y = 0.5

        return center_x, center_y

    def _calculate_advanced_geometry(self, gray: np.ndarray) -> Dict[str, float]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§Ø­Ø©
        area = float(np.sum(gray > 50))

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø­ÙŠØ· (ØªÙ‚Ø¯ÙŠØ± Ù…Ø¨Ø³Ø·)
        edges = self._simple_edge_detection(gray)
        perimeter = float(np.sum(edges > 0))

        # Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹Ø±Ø¶ Ù„Ù„Ø§Ø±ØªÙØ§Ø¹
        height, width = gray.shape
        aspect_ratio = width / height if height > 0 else 1.0

        # Ø§Ù„Ø§Ø³ØªØ¯Ø§Ø±Ø©
        roundness = (4 * math.pi * area) / (perimeter * perimeter) if perimeter > 0 else 0

        # Ø§Ù„ÙƒØ«Ø§ÙØ©
        compactness = area / (width * height) if (width * height) > 0 else 0

        # Ø§Ù„Ø§Ø³ØªØ·Ø§Ù„Ø©
        elongation = max(width, height) / min(width, height) if min(width, height) > 0 else 1.0

        return {
            "area": area,
            "perimeter": perimeter,
            "aspect_ratio": aspect_ratio,
            "roundness": max(0, min(1, roundness)),
            "compactness": max(0, min(1, compactness)),
            "elongation": elongation
        }

    def _estimate_equation_parameters(self, gray: np.ndarray, geometric_features: Dict[str, float]) -> Dict[str, float]:
        """ØªÙ‚Ø¯ÙŠØ± Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©"""
        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©
        roundness = geometric_features["roundness"]
        aspect_ratio = geometric_features["aspect_ratio"]
        elongation = geometric_features["elongation"]

        # ØªÙ‚Ø¯ÙŠØ± Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¬Ø³Ù…
        body_curve_a = 0.5 + (roundness * 0.5)
        body_curve_b = 0.3 + (aspect_ratio * 0.3)

        # ØªÙ‚Ø¯ÙŠØ± Ù†ØµÙ Ø§Ù„Ù‚Ø·Ø±
        head_radius = 0.2 + (roundness * 0.2)

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø²Ø§ÙˆÙŠØ©
        ear_angle = 30.0 + (elongation * 20.0)

        # ØªÙ‚Ø¯ÙŠØ± Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø°ÙŠÙ„
        tail_curve = 0.8 + (aspect_ratio * 0.4)

        return {
            "body_curve_a": body_curve_a,
            "body_curve_b": body_curve_b,
            "head_radius": head_radius,
            "ear_angle": ear_angle,
            "tail_curve": tail_curve,
            "estimated_curve": roundness,
            "estimated_radius": head_radius,
            "estimated_angle": ear_angle
        }

    def _calculate_saturation(self, image: np.ndarray) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø¨Ø¹ Ø§Ù„Ù„ÙˆÙ†ÙŠ"""
        if len(image.shape) == 3:
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ HSV Ù…Ø¨Ø³Ø·
            r, g, b = image[:,:,0], image[:,:,1], image[:,:,2]
            max_val = np.maximum(np.maximum(r, g), b)
            min_val = np.minimum(np.minimum(r, g), b)

            saturation = np.where(max_val > 0, (max_val - min_val) / max_val, 0)
            return float(np.mean(saturation))

        return 0.0

    def _calculate_hue_range(self, image: np.ndarray) -> list:
        """Ø­Ø³Ø§Ø¨ Ù†Ø·Ø§Ù‚ Ø§Ù„ØµØ¨ØºØ©"""
        if len(image.shape) == 3:
            # ØªÙ‚Ø¯ÙŠØ± Ù…Ø¨Ø³Ø· Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ØµØ¨ØºØ©
            dominant_color = self._extract_dominant_color(image)
            r, g, b = dominant_color

            if g > r and g > b:
                return [60, 180]  # Ø£Ø®Ø¶Ø±
            elif r > g and r > b:
                return [0, 60]    # Ø£Ø­Ù…Ø±
            elif b > r and b > g:
                return [180, 300] # Ø£Ø²Ø±Ù‚
            else:
                return [0, 360]   # Ù…ØªÙ†ÙˆØ¹

        return [0, 360]

    def _calculate_orientation(self, gray: np.ndarray) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡"""
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø´ÙƒÙ„
        y_indices, x_indices = np.where(gray > 50)

        if len(x_indices) > 1 and len(y_indices) > 1:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PCA Ù…Ø¨Ø³Ø·
            center_x = np.mean(x_indices)
            center_y = np.mean(y_indices)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
            var_x = np.var(x_indices - center_x)
            var_y = np.var(y_indices - center_y)

            if var_x > var_y:
                return 0.0  # Ø£ÙÙ‚ÙŠ
            else:
                return 90.0  # Ø¹Ù…ÙˆØ¯ÙŠ

        return 0.0

    def _find_bounding_box(self, gray: np.ndarray) -> list:
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±Ø¨Ø¹ Ø§Ù„Ù…Ø­ÙŠØ·"""
        y_indices, x_indices = np.where(gray > 50)

        if len(x_indices) > 0 and len(y_indices) > 0:
            min_x = np.min(x_indices) / gray.shape[1]
            max_x = np.max(x_indices) / gray.shape[1]
            min_y = np.min(y_indices) / gray.shape[0]
            max_y = np.max(y_indices) / gray.shape[0]

            return [min_x, min_y, max_x, max_y]

        return [0.1, 0.1, 0.9, 0.9]

    def _simple_edge_detection(self, gray: np.ndarray) -> np.ndarray:
        """ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ù…Ø¨Ø³Ø·"""
        if CV2_AVAILABLE:
            return cv2.Canny(gray, 50, 150)
        else:
            # Ù…Ø±Ø´Ø­ Sobel Ù…Ø¨Ø³Ø·
            kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
            kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª
            edges_x = self._convolve2d(gray, kernel_x)
            edges_y = self._convolve2d(gray, kernel_y)

            # Ø­Ø³Ø§Ø¨ Ù‚ÙˆØ© Ø§Ù„Ø­Ø§ÙØ©
            edges = np.sqrt(edges_x**2 + edges_y**2)

            return edges

    def _convolve2d(self, image: np.ndarray, kernel: np.ndarray) -> np.ndarray:
        """ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­ Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯"""
        result = np.zeros_like(image, dtype=np.float32)

        for i in range(1, image.shape[0] - 1):
            for j in range(1, image.shape[1] - 1):
                result[i, j] = np.sum(image[i-1:i+2, j-1:j+2] * kernel)

        return result

    def analyze_image_complexity(self, image: np.ndarray) -> Dict[str, float]:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©"""
        if len(image.shape) == 3:
            gray = np.mean(image, axis=2).astype(np.uint8)
        else:
            gray = image

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        edges = self._simple_edge_detection(gray)
        edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ†ÙˆØ¹ Ø§Ù„Ù„ÙˆÙ†ÙŠ
        if len(image.shape) == 3:
            unique_colors = len(np.unique(image.reshape(-1, 3), axis=0))
            color_diversity = unique_colors / (image.shape[0] * image.shape[1])
        else:
            color_diversity = 0.0

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ…Ø§Ø«Ù„
        symmetry_score = self._calculate_symmetry(gray)

        return {
            "edge_density": edge_density,
            "color_diversity": color_diversity,
            "symmetry_score": symmetry_score,
            "complexity_score": (edge_density + color_diversity) / 2
        }

    def _calculate_symmetry(self, gray: np.ndarray) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ…Ø§Ø«Ù„"""
        # ØªÙ…Ø§Ø«Ù„ Ø£ÙÙ‚ÙŠ
        left_half = gray[:, :gray.shape[1]//2]
        right_half = np.fliplr(gray[:, gray.shape[1]//2:])

        if left_half.shape == right_half.shape:
            horizontal_symmetry = 1.0 - np.mean(np.abs(left_half - right_half)) / 255.0
        else:
            horizontal_symmetry = 0.0

        return max(0, horizontal_symmetry)


def main():
    """Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠØ©"""
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠØ©...")

    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
    extractor_unit = RevolutionaryExtractorUnit()

    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§Ø®ØªØ¨Ø§Ø±
    test_image = np.zeros((200, 200, 3), dtype=np.uint8)
    # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø¨Ø³ÙŠØ·Ø©
    center = (100, 100)
    radius = 50
    color = (255, 200, 100)

    y, x = np.ogrid[:200, :200]
    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
    test_image[mask] = color

    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
    print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø®ØµØ§Ø¦Øµ...")
    result = extractor_unit.extract_equation_from_image(test_image)

    print(f"ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: {result['success']}")
    print(f"ğŸ”§ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©: {result['method']}")
    print(f"ğŸ“ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {result['message']}")

    if result["success"]:
        features = result["result"]
        print(f"ğŸ¨ Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†: {features['color_properties']['dominant_color']}")
        print(f"ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø­Ø©: {features['geometric_features']['area']:.1f}")
        print(f"ğŸ”„ Ø§Ù„Ø§Ø³ØªØ¯Ø§Ø±Ø©: {features['geometric_features']['roundness']:.3f}")

    # Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
    print("\nğŸ”¬ Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯...")
    complexity = extractor_unit.analyze_image_complexity(test_image)
    print(f"ğŸ“Š ÙƒØ«Ø§ÙØ© Ø§Ù„Ø­ÙˆØ§Ù: {complexity['edge_density']:.3f}")
    print(f"ğŸŒˆ Ø§Ù„ØªÙ†ÙˆØ¹ Ø§Ù„Ù„ÙˆÙ†ÙŠ: {complexity['color_diversity']:.3f}")
    print(f"ğŸ”„ Ø§Ù„ØªÙ…Ø§Ø«Ù„: {complexity['symmetry_score']:.3f}")


if __name__ == "__main__":
    main()
