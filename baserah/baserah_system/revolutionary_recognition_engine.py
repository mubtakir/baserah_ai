#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Revolutionary Recognition Engine for Basira System
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ - Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø©

Recognition engine implementing Basil Yahya Abdullah's revolutionary concept:
Smart recognition with tolerance thresholds and Euclidean distance.

Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø°ÙŠ ÙŠØ·Ø¨Ù‚ Ù…ÙÙ‡ÙˆÙ… Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø§Ù„Ø«ÙˆØ±ÙŠ:
Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø°ÙƒÙŠ Ù…Ø¹ Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ©.

Author: Basira System Development Team
Created by: Basil Yahya Abdullah - Iraq/Mosul
Version: 1.0.0
"""

import numpy as np
import math
import sqlite3
from datetime import datetime
from typing import Dict, List, Any

from revolutionary_database import RevolutionaryShapeDatabase, ShapeEntity
from revolutionary_extractor_unit import RevolutionaryExtractorUnit


class RevolutionaryRecognitionEngine:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ Ù…Ø¹ Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ©"""
    
    def __init__(self, shape_db: RevolutionaryShapeDatabase, 
                 extractor_unit: RevolutionaryExtractorUnit):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ"""
        self.shape_db = shape_db
        self.extractor_unit = extractor_unit
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ")
    
    def recognize_image(self, image: np.ndarray) -> Dict[str, Any]:
        """Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©"""
        print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©...")
        
        # 1. Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø®ØµØ§Ø¦Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        extraction_result = self.extractor_unit.extract_equation_from_image(image)
        
        if not extraction_result["success"]:
            return {
                "status": "ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·",
                "confidence": 0.0,
                "message": "Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø®ØµØ§Ø¦Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©"
            }
        
        extracted_features = extraction_result["result"]
        
        # 2. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        known_shapes = self.shape_db.get_all_shapes()
        
        # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ ÙƒÙ„ Ø´ÙƒÙ„
        recognition_candidates = []
        
        for shape in known_shapes:
            similarity_score = self._calculate_revolutionary_similarity(
                extracted_features, shape
            )
            
            # ÙØ­Øµ Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ©
            within_tolerance = self._check_tolerance_thresholds(
                similarity_score, shape.tolerance_thresholds
            )
            
            recognition_candidates.append({
                "shape": shape,
                "similarity_score": similarity_score,
                "within_tolerance": within_tolerance,
                "euclidean_distance": similarity_score["euclidean_distance"],
                "geometric_match": similarity_score["geometric_similarity"],
                "color_match": similarity_score["color_similarity"]
            })
        
        # 4. ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚
        recognition_candidates.sort(key=lambda x: x["euclidean_distance"])
        
        # 5. ØªØ­Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚
        best_match = recognition_candidates[0] if recognition_candidates else None
        
        if best_match and best_match["within_tolerance"]:
            # ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¨Ù†Ø¬Ø§Ø­
            confidence = self._calculate_confidence(best_match["similarity_score"])
            
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø±Ù
            self._log_recognition(image, best_match["shape"], confidence, 
                                best_match["euclidean_distance"])
            
            return {
                "status": "ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¨Ù†Ø¬Ø§Ø­",
                "recognized_shape": best_match["shape"].name,
                "category": best_match["shape"].category,
                "confidence": confidence,
                "euclidean_distance": best_match["euclidean_distance"],
                "geometric_similarity": best_match["geometric_match"],
                "color_similarity": best_match["color_match"],
                "extraction_method": extraction_result["method"],
                "description": self._generate_description(best_match["shape"], 
                                                        recognition_candidates),
                "all_candidates": recognition_candidates[:5]  # Ø£ÙØ¶Ù„ 5
            }
        else:
            # Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù
            return {
                "status": "Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù",
                "confidence": 0.0,
                "closest_match": best_match["shape"].name if best_match else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                "euclidean_distance": best_match["euclidean_distance"] if best_match else float('inf'),
                "extraction_method": extraction_result["method"],
                "all_candidates": recognition_candidates[:5],
                "message": "Ø§Ù„ØµÙˆØ±Ø© Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ© Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„Ø©"
            }
    
    def _calculate_revolutionary_similarity(self, extracted_features: Dict[str, Any], 
                                          known_shape: ShapeEntity) -> Dict[str, float]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø«ÙˆØ±ÙŠ"""
        
        # 1. Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠ
        geometric_sim = self._calculate_geometric_similarity(
            extracted_features.get("geometric_features", {}),
            known_shape.geometric_features
        )
        
        # 2. Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù„ÙˆÙ†ÙŠ
        color_sim = self._calculate_color_similarity(
            extracted_features.get("color_properties", {}),
            known_shape.color_properties
        )
        
        # 3. Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠ
        position_sim = self._calculate_position_similarity(
            extracted_features.get("position_info", {}),
            known_shape.position_info
        )
        
        # 4. Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© (ØªØ·Ø¨ÙŠÙ‚ ÙÙƒØ±Ø© Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡)
        euclidean_distance = math.sqrt(
            geometric_sim**2 * 0.5 +
            color_sim**2 * 0.3 +
            position_sim**2 * 0.2
        )
        
        return {
            "geometric_similarity": geometric_sim,
            "color_similarity": color_sim,
            "position_similarity": position_sim,
            "euclidean_distance": euclidean_distance
        }
    
    def _calculate_geometric_similarity(self, extracted: Dict[str, float], 
                                      known: Dict[str, float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠ"""
        differences = []
        
        common_features = ["area", "perimeter", "aspect_ratio", "roundness", "compactness"]
        
        for feature in common_features:
            if feature in extracted and feature in known:
                if known[feature] != 0:
                    diff = abs(extracted[feature] - known[feature]) / abs(known[feature])
                else:
                    diff = abs(extracted[feature])
                differences.append(diff)
        
        return np.mean(differences) if differences else 1.0
    
    def _calculate_color_similarity(self, extracted: Dict[str, Any], 
                                   known: Dict[str, Any]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù„ÙˆÙ†ÙŠ"""
        if "dominant_color" not in extracted or "dominant_color" not in known:
            return 1.0
        
        extracted_color = np.array(extracted["dominant_color"])
        known_color = np.array(known["dominant_color"])
        
        # Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ© ÙÙŠ ÙØ¶Ø§Ø¡ RGB
        color_distance = np.linalg.norm(extracted_color - known_color)
        
        # ØªØ·Ø¨ÙŠØ¹ (0-1)
        normalized_distance = color_distance / (255 * math.sqrt(3))
        
        return normalized_distance
    
    def _calculate_position_similarity(self, extracted: Dict[str, float], 
                                     known: Dict[str, float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠ"""
        if "center_x" not in extracted or "center_x" not in known:
            return 0.5
        
        pos_diff_x = abs(extracted["center_x"] - known["center_x"])
        pos_diff_y = abs(extracted["center_y"] - known["center_y"])
        
        return math.sqrt(pos_diff_x**2 + pos_diff_y**2)
    
    def _check_tolerance_thresholds(self, similarity_score: Dict[str, float], 
                                   thresholds: Dict[str, float]) -> bool:
        """ÙØ­Øµ Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ© - ØªØ·Ø¨ÙŠÙ‚ ÙÙƒØ±Ø© Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡"""
        
        # ÙØ­Øµ Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ© Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©
        geometric_ok = (similarity_score["geometric_similarity"] <= 
                       thresholds.get("geometric_tolerance", 0.2))
        
        # ÙØ­Øµ Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ© Ø§Ù„Ù„ÙˆÙ†ÙŠØ©
        color_ok = (similarity_score["color_similarity"] <= 
                   thresholds.get("color_tolerance", 50.0) / 255.0)
        
        # ÙØ­Øµ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ© (Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø«ÙˆØ±ÙŠØ©)
        euclidean_ok = (similarity_score["euclidean_distance"] <= 
                       thresholds.get("euclidean_distance", 0.3))
        
        # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø±ÙˆØ· Ù…Ø­Ù‚Ù‚Ø©
        return geometric_ok and color_ok and euclidean_ok
    
    def _calculate_confidence(self, similarity_score: Dict[str, float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
        # ÙƒÙ„Ù…Ø§ Ù‚Ù„Øª Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ©ØŒ Ø²Ø§Ø¯Øª Ø§Ù„Ø«Ù‚Ø©
        euclidean_dist = similarity_score["euclidean_distance"]
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¥Ù„Ù‰ Ù†Ø³Ø¨Ø© Ø«Ù‚Ø© (0-1)
        confidence = max(0.0, 1.0 - euclidean_dist)
        
        return min(1.0, confidence)
    
    def _generate_description(self, recognized_shape: ShapeEntity, 
                            all_candidates: List[Dict]) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ÙˆØµÙ Ø°ÙƒÙŠ Ù„Ù„Ù†ØªÙŠØ¬Ø© - ØªØ·Ø¨ÙŠÙ‚ ÙÙƒØ±Ø© Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡"""
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
        categories_found = set()
        colors_found = set()
        postures_found = set()
        
        for candidate in all_candidates[:3]:  # Ø£ÙØ¶Ù„ 3
            if candidate["within_tolerance"]:
                categories_found.add(candidate["shape"].category)
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
                color = candidate["shape"].color_properties["dominant_color"]
                if color[0] > 200 and color[1] > 200 and color[2] > 200:
                    colors_found.add("Ø£Ø¨ÙŠØ¶")
                elif color[0] < 50 and color[1] < 50 and color[2] < 50:
                    colors_found.add("Ø£Ø³ÙˆØ¯")
                elif color[1] > color[0] and color[1] > color[2]:
                    colors_found.add("Ø£Ø®Ø¶Ø±")
                elif color[0] > color[1] and color[0] > color[2]:
                    colors_found.add("Ø£Ø­Ù…Ø±")
                elif color[2] > color[0] and color[2] > color[1]:
                    colors_found.add("Ø£Ø²Ø±Ù‚")
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ÙŠØ§Øª
                if "ÙˆØ§Ù‚ÙØ©" in candidate["shape"].name:
                    postures_found.add("ÙˆØ§Ù‚ÙØ©")
                elif "Ù†Ø§Ø¦Ù…Ø©" in candidate["shape"].name:
                    postures_found.add("Ù†Ø§Ø¦Ù…Ø©")
                elif "Ø¬Ø§Ù„Ø³Ø©" in candidate["shape"].name:
                    postures_found.add("Ø¬Ø§Ù„Ø³Ø©")
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙˆØµÙ Ø§Ù„Ø°ÙƒÙŠ (ØªØ·Ø¨ÙŠÙ‚ ÙÙƒØ±Ø© Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡)
        description = f"Ù‡Ø°Ø§ {recognized_shape.name}"
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¶Ø¹ÙŠØ©
        if postures_found:
            posture = list(postures_found)[0]
            if posture not in description:
                description += f" {posture}"
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚
        if len(categories_found) > 1:
            other_categories = [cat for cat in categories_found if cat != recognized_shape.category]
            if other_categories:
                if "Ø£Ø´Ø¬Ø§Ø±" in recognized_shape.name or any("Ø´Ø¬Ø±Ø©" in cat for cat in other_categories):
                    description += " Ø¨Ø®Ù„ÙÙŠØ© Ø£Ø´Ø¬Ø§Ø±"
                elif "Ø¨ÙŠÙˆØª" in recognized_shape.name or any("Ù…Ø¨Ø§Ù†ÙŠ" in cat for cat in other_categories):
                    description += " Ø¨Ø®Ù„ÙÙŠØ© Ø¨ÙŠÙˆØª"
                else:
                    description += f" ÙÙŠ Ù…Ø´Ù‡Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {', '.join(other_categories)}"
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        if len(colors_found) > 1:
            description += f" ÙˆØ£Ù„ÙˆØ§Ù† {', '.join(colors_found)}"
        
        return description
    
    def _log_recognition(self, image: np.ndarray, shape: ShapeEntity, 
                        confidence: float, similarity_score: float):
        """ØªØ³Ø¬ÙŠÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¹Ø±Ù ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # Ø­Ø³Ø§Ø¨ hash Ù„Ù„ØµÙˆØ±Ø©
            image_hash = str(hash(image.tobytes()))
            
            conn = sqlite3.connect(self.shape_db.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
            INSERT INTO recognition_history (input_image_hash, recognized_shape_id,
                                           confidence_score, similarity_score, recognition_date)
            VALUES (?, ?, ?, ?, ?)
            ''', (
                image_hash,
                shape.id,
                confidence,
                similarity_score,
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ¹Ø±Ù: {e}")
    
    def get_recognition_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¹Ø±Ù"""
        try:
            conn = sqlite3.connect(self.shape_db.db_path)
            cursor = conn.cursor()
            
            # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØ¹Ø±Ù
            cursor.execute('SELECT COUNT(*) FROM recognition_history')
            total_recognitions = cursor.fetchone()[0]
            
            # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©
            cursor.execute('SELECT AVG(confidence_score) FROM recognition_history')
            avg_confidence = cursor.fetchone()[0] or 0.0
            
            # Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ø£ÙƒØ«Ø± ØªØ¹Ø±ÙØ§Ù‹
            cursor.execute('''
            SELECT rs.name, COUNT(*) as count
            FROM recognition_history rh
            JOIN revolutionary_shapes rs ON rh.recognized_shape_id = rs.id
            GROUP BY rs.name
            ORDER BY count DESC
            LIMIT 5
            ''')
            top_shapes = cursor.fetchall()
            
            conn.close()
            
            return {
                "total_recognitions": total_recognitions,
                "average_confidence": avg_confidence,
                "top_recognized_shapes": top_shapes
            }
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
            return {}
    
    def batch_recognize(self, images: List[np.ndarray]) -> List[Dict[str, Any]]:
        """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±"""
        results = []
        
        print(f"ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ {len(images)} ØµÙˆØ±Ø©...")
        
        for i, image in enumerate(images):
            print(f"ğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© {i+1}/{len(images)}...")
            result = self.recognize_image(image)
            results.append(result)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
        successful_recognitions = sum(1 for r in results if r["status"] == "ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¨Ù†Ø¬Ø§Ø­")
        avg_confidence = np.mean([r["confidence"] for r in results if r["confidence"] > 0])
        
        print(f"âœ… ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ {successful_recognitions}/{len(images)} ØµÙˆØ±Ø©")
        print(f"ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {avg_confidence:.2%}")
        
        return results
    
    def fine_tune_thresholds(self, test_images: List[np.ndarray], 
                           expected_results: List[str]) -> Dict[str, float]:
        """Ø¶Ø¨Ø· Ø¯Ù‚ÙŠÙ‚ Ù„Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ©"""
        print("ğŸ”§ Ø¨Ø¯Ø¡ Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø³Ù…Ø§Ø­ÙŠØ©...")
        
        best_thresholds = {
            "geometric_tolerance": 0.2,
            "color_tolerance": 50.0,
            "euclidean_distance": 0.3
        }
        
        best_accuracy = 0.0
        
        # ØªØ¬Ø±ÙŠØ¨ Ù‚ÙŠÙ… Ù…Ø®ØªÙ„ÙØ© Ù„Ù„Ø¹ØªØ¨Ø§Øª
        for geo_tol in [0.1, 0.15, 0.2, 0.25, 0.3]:
            for color_tol in [30.0, 40.0, 50.0, 60.0, 70.0]:
                for eucl_dist in [0.2, 0.25, 0.3, 0.35, 0.4]:
                    
                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹ØªØ¨Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¤Ù‚ØªØ§Ù‹
                    temp_accuracy = self._test_thresholds(
                        test_images, expected_results,
                        geo_tol, color_tol, eucl_dist
                    )
                    
                    if temp_accuracy > best_accuracy:
                        best_accuracy = temp_accuracy
                        best_thresholds = {
                            "geometric_tolerance": geo_tol,
                            "color_tolerance": color_tol,
                            "euclidean_distance": eucl_dist
                        }
        
        print(f"âœ… Ø£ÙØ¶Ù„ Ø¹ØªØ¨Ø§Øª: {best_thresholds}")
        print(f"ğŸ“ˆ Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {best_accuracy:.2%}")
        
        return best_thresholds
    
    def _test_thresholds(self, test_images: List[np.ndarray], 
                        expected_results: List[str],
                        geo_tol: float, color_tol: float, eucl_dist: float) -> float:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¹ØªØ¨Ø§Øª Ù…Ø¹ÙŠÙ†Ø©"""
        correct = 0
        
        for image, expected in zip(test_images, expected_results):
            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¹ØªØ¨Ø§Øª Ù…Ø¤Ù‚ØªØ§Ù‹
            shapes = self.shape_db.get_all_shapes()
            for shape in shapes:
                shape.tolerance_thresholds.update({
                    "geometric_tolerance": geo_tol,
                    "color_tolerance": color_tol,
                    "euclidean_distance": eucl_dist
                })
            
            result = self.recognize_image(image)
            if result["status"] == "ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¨Ù†Ø¬Ø§Ø­" and result["recognized_shape"] == expected:
                correct += 1
        
        return correct / len(test_images) if test_images else 0.0


def main():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ"""
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø«ÙˆØ±ÙŠ...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
    from revolutionary_database import RevolutionaryShapeDatabase
    from revolutionary_extractor_unit import RevolutionaryExtractorUnit
    
    shape_db = RevolutionaryShapeDatabase()
    extractor_unit = RevolutionaryExtractorUnit()
    recognition_engine = RevolutionaryRecognitionEngine(shape_db, extractor_unit)
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§Ø®ØªØ¨Ø§Ø±
    test_image = np.zeros((200, 200, 3), dtype=np.uint8)
    # Ø±Ø³Ù… Ø´ÙƒÙ„ Ø¨Ø³ÙŠØ·
    test_image[50:150, 50:150] = [255, 255, 255]  # Ù…Ø±Ø¨Ø¹ Ø£Ø¨ÙŠØ¶
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ¹Ø±Ù
    print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ¹Ø±Ù...")
    result = recognition_engine.recognize_image(test_image)
    
    print(f"ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©: {result['status']}")
    if result['status'] == "ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¨Ù†Ø¬Ø§Ø­":
        print(f"ğŸ¯ Ø§Ù„Ø´ÙƒÙ„: {result['recognized_shape']}")
        print(f"ğŸ“ˆ Ø§Ù„Ø«Ù‚Ø©: {result['confidence']:.2%}")
        print(f"ğŸ“ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ©: {result['euclidean_distance']:.4f}")
        print(f"ğŸ“ Ø§Ù„ÙˆØµÙ: {result['description']}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    stats = recognition_engine.get_recognition_statistics()
    print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¹Ø±Ù:")
    print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª: {stats.get('total_recognitions', 0)}")
    print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {stats.get('average_confidence', 0):.2%}")


if __name__ == "__main__":
    main()
