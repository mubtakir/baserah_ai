#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Expert-Guided Arabic Rhetoric Analyzer - Part 3: Rhetorical Analysis
Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ± - Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù„Ø«: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ

Revolutionary integration of Expert/Explorer guidance with Arabic rhetorical analysis,
applying adaptive mathematical equations to achieve superior literary understanding.

Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ
ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ù…ØªÙƒÙŠÙØ© Ù„ØªØ­Ù‚ÙŠÙ‚ ÙÙ‡Ù… Ø£Ø¯Ø¨ÙŠ Ù…ØªÙÙˆÙ‚.

Author: Basil Yahya Abdullah - Iraq/Mosul
Version: 1.0.0 - REVOLUTIONARY ARABIC RHETORIC
"""

import numpy as np
import sys
import os
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass
import json
from datetime import datetime
import re

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒÙŠÙ Ù„Ù„Ø¨Ù„Ø§ØºØ©
class MockRhetoricEquation:
    def __init__(self, name: str, input_dim: int, output_dim: int):
        self.name = name
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.current_complexity = 15  # Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹Ù‚Ø¯Ø© Ø¬Ø¯Ø§Ù‹
        self.adaptation_count = 0
        self.rhetoric_accuracy = 0.4  # Ø¯Ù‚Ø© Ø¨Ù„Ø§ØºÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ©
        self.metaphor_detection = 0.5
        self.simile_recognition = 0.55
        self.alliteration_analysis = 0.45
        self.rhythm_detection = 0.4
        self.eloquence_measurement = 0.35
        self.literary_beauty_assessment = 0.3

    def adapt_with_expert_guidance(self, guidance, analysis):
        self.adaptation_count += 1
        if hasattr(guidance, 'recommended_evolution'):
            if guidance.recommended_evolution == "increase":
                self.current_complexity += 5
                self.rhetoric_accuracy += 0.08
                self.metaphor_detection += 0.06
                self.simile_recognition += 0.05
                self.alliteration_analysis += 0.07
                self.rhythm_detection += 0.06
                self.eloquence_measurement += 0.08
                self.literary_beauty_assessment += 0.09
            elif guidance.recommended_evolution == "restructure":
                self.rhetoric_accuracy += 0.04
                self.metaphor_detection += 0.03
                self.simile_recognition += 0.02

    def get_expert_guidance_summary(self):
        return {
            "current_complexity": self.current_complexity,
            "total_adaptations": self.adaptation_count,
            "rhetoric_accuracy": self.rhetoric_accuracy,
            "metaphor_detection": self.metaphor_detection,
            "simile_recognition": self.simile_recognition,
            "alliteration_analysis": self.alliteration_analysis,
            "rhythm_detection": self.rhythm_detection,
            "eloquence_measurement": self.eloquence_measurement,
            "literary_beauty_assessment": self.literary_beauty_assessment,
            "average_improvement": 0.06 * self.adaptation_count
        }

class MockRhetoricGuidance:
    def __init__(self, target_complexity, focus_areas, adaptation_strength, priority_functions, recommended_evolution):
        self.target_complexity = target_complexity
        self.focus_areas = focus_areas
        self.adaptation_strength = adaptation_strength
        self.priority_functions = priority_functions
        self.recommended_evolution = recommended_evolution

class MockRhetoricAnalysis:
    def __init__(self, rhetoric_accuracy, metaphor_clarity, literary_coherence, eloquence_precision, areas_for_improvement):
        self.rhetoric_accuracy = rhetoric_accuracy
        self.metaphor_clarity = metaphor_clarity
        self.literary_coherence = literary_coherence
        self.eloquence_precision = eloquence_precision
        self.areas_for_improvement = areas_for_improvement

@dataclass
class RhetoricAnalysisRequest:
    """Ø·Ù„Ø¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ"""
    text: str
    context: str = ""
    analysis_depth: str = "comprehensive"  # "basic", "intermediate", "comprehensive"
    rhetoric_aspects: List[str] = None  # ["metaphor", "simile", "alliteration", "rhythm", "eloquence"]
    expert_guidance_level: str = "adaptive"
    learning_enabled: bool = True

@dataclass
class RhetoricalDevice:
    """Ø¬Ù‡Ø§Ø² Ø¨Ù„Ø§ØºÙŠ"""
    device_type: str
    text_span: str
    description: str
    literary_effect: str
    beauty_score: float
    confidence: float

@dataclass
class RhetoricAnalysisResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ"""
    success: bool
    text: str
    literary_style: str  # Ø£Ø³Ù„ÙˆØ¨ Ø£Ø¯Ø¨ÙŠ
    rhetorical_devices: List[RhetoricalDevice]
    eloquence_score: float
    beauty_assessment: Dict[str, float]
    rhythm_analysis: Dict[str, Any]
    overall_rhetoric_quality: float
    expert_guidance_applied: Dict[str, Any] = None
    equation_adaptations: Dict[str, Any] = None
    performance_improvements: Dict[str, float] = None
    learning_insights: List[str] = None
    next_cycle_recommendations: List[str] = None

class ExpertGuidedArabicRhetoricAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ø«ÙˆØ±ÙŠ"""

    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ±"""
        print("ğŸŒŸ" + "="*100 + "ğŸŒŸ")
        print("ğŸ¨ Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ø«ÙˆØ±ÙŠ")
        print("ğŸ“œ Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù ÙŠÙ‚ÙˆØ¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø°ÙƒØ§Ø¡")
        print("ğŸ§® Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø±ÙŠØ§Ø¶ÙŠØ© Ù…ØªÙƒÙŠÙØ© + ØªØ­Ù„ÙŠÙ„ Ø¨Ù„Ø§ØºÙŠ Ù…ØªÙ‚Ø¯Ù…")
        print("ğŸŒŸ Ø¥Ø¨Ø¯Ø§Ø¹ Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ù…Ù† Ø§Ù„Ø¹Ø±Ø§Ù‚/Ø§Ù„Ù…ÙˆØµÙ„ ğŸŒŸ")
        print("ğŸŒŸ" + "="*100 + "ğŸŒŸ")

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…ØªØ®ØµØµØ©
        self.rhetoric_equations = {
            "metaphor_detector": MockRhetoricEquation("metaphor_detection", 35, 28),
            "simile_analyzer": MockRhetoricEquation("simile_analysis", 32, 25),
            "alliteration_finder": MockRhetoricEquation("alliteration_finding", 28, 22),
            "rhythm_analyzer": MockRhetoricEquation("rhythm_analysis", 30, 24),
            "eloquence_measurer": MockRhetoricEquation("eloquence_measurement", 40, 32),
            "beauty_assessor": MockRhetoricEquation("beauty_assessment", 45, 36),
            "literary_style_classifier": MockRhetoricEquation("style_classification", 38, 30),
            "poetic_meter_detector": MockRhetoricEquation("meter_detection", 33, 26),
            "semantic_harmony_analyzer": MockRhetoricEquation("semantic_harmony", 36, 28),
            "artistic_imagery_extractor": MockRhetoricEquation("imagery_extraction", 42, 34),
            "emotional_impact_measurer": MockRhetoricEquation("emotional_impact", 39, 31),
            "linguistic_elegance_evaluator": MockRhetoricEquation("elegance_evaluation", 44, 35)
        }

        # Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        self.rhetoric_laws = {
            "eloquence_harmony": {
                "name": "ØªÙ†Ø§ØºÙ… Ø§Ù„ÙØµØ§Ø­Ø©",
                "description": "Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø¨Ù„ÙŠØº ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø¬Ù…Ø§Ù„ Ø§Ù„Ù„ÙØ¸ ÙˆÙˆØ¶ÙˆØ­ Ø§Ù„Ù…Ø¹Ù†Ù‰",
                "formula": "Eloquence = Beauty(words) Ã— Clarity(meaning)"
            },
            "metaphor_appropriateness": {
                "name": "Ù…Ù†Ø§Ø³Ø¨Ø© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø©",
                "description": "Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø© Ø§Ù„Ø¬ÙŠØ¯Ø© ØªÙ‚Ø±Ø¨ Ø§Ù„Ù…Ø¹Ù†Ù‰ ÙˆØªØ²ÙŠØ¯ Ø§Ù„Ø¬Ù…Ø§Ù„",
                "formula": "Metaphor_Quality = Similarity(tenor, vehicle) Ã— Beauty_Enhancement"
            },
            "rhythm_consistency": {
                "name": "Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹",
                "description": "Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ Ø§Ù„Ù…ØªØ³Ù‚ ÙŠØ²ÙŠØ¯ Ù…Ù† Ø¬Ù…Ø§Ù„ Ø§Ù„Ù†Øµ ÙˆØªØ£Ø«ÙŠØ±Ù‡",
                "formula": "Rhythm_Quality = Consistency(meter) Ã— Musical_Effect"
            }
        }

        # Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        self.rhetoric_constants = {
            "metaphor_weight": 0.9,
            "simile_weight": 0.8,
            "alliteration_weight": 0.7,
            "rhythm_weight": 0.85,
            "eloquence_threshold": 0.75,
            "beauty_standard": 0.8
        }

        # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        self.arabic_rhetorical_devices = self._load_arabic_rhetorical_devices()

        # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø´Ø¹Ø±ÙŠØ©
        self.arabic_meters = self._load_arabic_meters()

        # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©
        self.arabic_literary_styles = self._load_arabic_literary_styles()

        # ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©
        self.rhetoric_history = []
        self.rhetoric_learning_database = {}

        print("ğŸ¨ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ®ØµØµØ©:")
        for eq_name in self.rhetoric_equations.keys():
            print(f"   âœ… {eq_name}")

        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ±!")

    def _load_arabic_rhetorical_devices(self) -> Dict[str, Dict[str, Any]]:
        """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
        return {
            "Ø§Ø³ØªØ¹Ø§Ø±Ø©": {"type": "Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†", "effect": "ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¹Ù†Ù‰ ÙˆØ²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¬Ù…Ø§Ù„", "examples": ["Ø§Ù„Ø¨Ø­Ø± ÙŠØ¶Ø­Ùƒ", "Ø§Ù„Ù„ÙŠÙ„ ÙŠØ¨ÙƒÙŠ"]},
            "ØªØ´Ø¨ÙŠÙ‡": {"type": "Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†", "effect": "ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø¨Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©", "examples": ["ÙƒØ§Ù„Ø£Ø³Ø¯ ÙÙŠ Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©", "ÙƒØ§Ù„Ø¨Ø¯Ø± ÙÙŠ Ø§Ù„Ø¬Ù…Ø§Ù„"]},
            "ÙƒÙ†Ø§ÙŠØ©": {"type": "Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†", "effect": "Ø§Ù„ØªØ¹Ø¨ÙŠØ± ØºÙŠØ± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±", "examples": ["Ø·ÙˆÙŠÙ„ Ø§Ù„Ù†Ø¬Ø§Ø¯", "ÙƒØ«ÙŠØ± Ø§Ù„Ø±Ù…Ø§Ø¯"]},
            "Ø¬Ù†Ø§Ø³": {"type": "Ø¹Ù„Ù… Ø§Ù„Ø¨Ø¯ÙŠØ¹", "effect": "Ø§Ù„Ø¬Ù…Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ", "examples": ["ÙˆÙŠÙˆÙ… ØªÙˆÙÙ‰ Ø§Ù„Ø±Ø³ÙˆÙ„ ÙˆØªÙˆÙÙ‰", "ØµÙ„ÙŠØª Ø§Ù„Ù…ØºØ±Ø¨ ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨"]},
            "Ø·Ø¨Ø§Ù‚": {"type": "Ø¹Ù„Ù… Ø§Ù„Ø¨Ø¯ÙŠØ¹", "effect": "Ø§Ù„ØªØ¶Ø§Ø¯ ÙˆØ§Ù„ØªÙˆØ§Ø²Ù†", "examples": ["Ø§Ù„Ù„ÙŠÙ„ ÙˆØ§Ù„Ù†Ù‡Ø§Ø±", "Ø§Ù„Ø­Ø¨ ÙˆØ§Ù„ÙƒØ±Ù‡"]},
            "Ø³Ø¬Ø¹": {"type": "Ø¹Ù„Ù… Ø§Ù„Ø¨Ø¯ÙŠØ¹", "effect": "Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ÙˆØ§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰", "examples": ["ÙÙŠ Ø§Ù„ØµÙŠÙ Ø¶ÙŠÙ", "Ø§Ù„Ø¹Ù„Ù… Ù†ÙˆØ± ÙˆØ§Ù„Ø¬Ù‡Ù„ Ø¸Ù„Ø§Ù…"]}
        }

    def _load_arabic_meters(self) -> Dict[str, Dict[str, Any]]:
        """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø´Ø¹Ø±ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
        return {
            "Ø§Ù„Ø·ÙˆÙŠÙ„": {"pattern": "ÙØ¹ÙˆÙ„Ù† Ù…ÙØ§Ø¹ÙŠÙ„Ù† ÙØ¹ÙˆÙ„Ù† Ù…ÙØ§Ø¹ÙŠÙ„Ù†", "usage": "Ø§Ù„Ø´Ø¹Ø± Ø§Ù„Ø¬Ø§Ù‡Ù„ÙŠ ÙˆØ§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ", "mood": "Ø¬Ø¯ÙŠ ÙˆÙ‚ÙˆÙŠ"},
            "Ø§Ù„Ø¨Ø³ÙŠØ·": {"pattern": "Ù…Ø³ØªÙØ¹Ù„Ù† ÙØ§Ø¹Ù„Ù† Ù…Ø³ØªÙØ¹Ù„Ù† ÙØ§Ø¹Ù„Ù†", "usage": "Ø§Ù„Ø´Ø¹Ø± Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ", "mood": "ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø§Ø´Ø±"},
            "Ø§Ù„ÙˆØ§ÙØ±": {"pattern": "Ù…ÙØ§Ø¹Ù„ØªÙ† Ù…ÙØ§Ø¹Ù„ØªÙ† Ù…ÙØ§Ø¹Ù„ØªÙ†", "usage": "Ø§Ù„ØºØ²Ù„ ÙˆØ§Ù„ÙˆØµÙ", "mood": "Ø¹Ø°Ø¨ ÙˆØ±Ù‚ÙŠÙ‚"},
            "Ø§Ù„ÙƒØ§Ù…Ù„": {"pattern": "Ù…ØªÙØ§Ø¹Ù„Ù† Ù…ØªÙØ§Ø¹Ù„Ù† Ù…ØªÙØ§Ø¹Ù„Ù†", "usage": "Ø§Ù„Ø­Ù…Ø§Ø³Ø© ÙˆØ§Ù„ÙØ®Ø±", "mood": "Ù‚ÙˆÙŠ ÙˆÙ…ØªØ¯ÙÙ‚"},
            "Ø§Ù„Ø±Ø¬Ø²": {"pattern": "Ù…Ø³ØªÙØ¹Ù„Ù† Ù…Ø³ØªÙØ¹Ù„Ù† Ù…Ø³ØªÙØ¹Ù„Ù†", "usage": "Ø§Ù„Ø´Ø¹Ø± Ø§Ù„Ø´Ø¹Ø¨ÙŠ", "mood": "Ø¨Ø³ÙŠØ· ÙˆØ³Ù‡Ù„"},
            "Ø§Ù„Ù…ØªÙ‚Ø§Ø±Ø¨": {"pattern": "ÙØ¹ÙˆÙ„Ù† ÙØ¹ÙˆÙ„Ù† ÙØ¹ÙˆÙ„Ù† ÙØ¹ÙˆÙ„Ù†", "usage": "Ø§Ù„Ø´Ø¹Ø± Ø§Ù„ØµÙˆÙÙŠ", "mood": "Ù‡Ø§Ø¯Ø¦ ÙˆÙ…ØªØ£Ù…Ù„"}
        }

    def _load_arabic_literary_styles(self) -> Dict[str, Dict[str, Any]]:
        """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
        return {
            "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¬Ø§Ù‡Ù„ÙŠ": {"features": ["Ù‚ÙˆØ© Ø§Ù„Ù„ÙØ¸", "ØµØ¯Ù‚ Ø§Ù„Ø¹Ø§Ø·ÙØ©", "ÙˆØ¶ÙˆØ­ Ø§Ù„Ù…Ø¹Ù†Ù‰"], "period": "Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…"},
            "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ": {"features": ["Ø§Ù„Ø³Ù‡ÙˆÙ„Ø©", "Ø§Ù„ÙˆØ¶ÙˆØ­", "Ø§Ù„ØªØ£Ø«ÙŠØ±"], "period": "ØµØ¯Ø± Ø§Ù„Ø¥Ø³Ù„Ø§Ù…"},
            "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ù…ÙˆÙŠ": {"features": ["Ø§Ù„Ø±Ù‚Ø©", "Ø§Ù„Ø¹Ø°ÙˆØ¨Ø©", "Ø§Ù„ØªÙ†ÙˆØ¹"], "period": "Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø£Ù…ÙˆÙŠ"},
            "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠ": {"features": ["Ø§Ù„ØªØ¹Ù‚ÙŠØ¯", "Ø§Ù„Ø²Ø®Ø±ÙØ©", "Ø§Ù„ØªÙ†ÙˆØ¹"], "period": "Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠ"},
            "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ù†Ø¯Ù„Ø³ÙŠ": {"features": ["Ø§Ù„Ø±Ù‚Ø©", "Ø§Ù„Ø¬Ù…Ø§Ù„", "Ø§Ù„Ø·Ø¨ÙŠØ¹Ø©"], "period": "Ø§Ù„Ø£Ù†Ø¯Ù„Ø³"},
            "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø­Ø¯ÙŠØ«": {"features": ["Ø§Ù„ØªØ¬Ø¯ÙŠØ¯", "Ø§Ù„Ø¨Ø³Ø§Ø·Ø©", "Ø§Ù„ÙˆØ¶ÙˆØ­"], "period": "Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø¯ÙŠØ«"}
        }

    def analyze_rhetoric_with_expert_guidance(self, request: RhetoricAnalysisRequest) -> RhetoricAnalysisResult:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ±"""
        print(f"\nğŸ¨ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ± Ù„Ù„Ù†Øµ: {request.text[:50]}...")
        start_time = datetime.now()

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨ÙŠØ± Ù„Ù„Ø·Ù„Ø¨ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
        expert_analysis = self._analyze_rhetoric_request_with_expert(request)
        print(f"ğŸ“œ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ø¨Ù„Ø§ØºÙŠ: {expert_analysis['complexity_assessment']}")

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªÙˆÙ„ÙŠØ¯ ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ø§Ù„Ø®Ø¨ÙŠØ± Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ©
        expert_guidance = self._generate_rhetoric_expert_guidance(request, expert_analysis)
        print(f"ğŸ¨ ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ø¨Ù„Ø§ØºÙŠ: {expert_guidance.recommended_evolution}")

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: ØªÙƒÙŠÙ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ©
        equation_adaptations = self._adapt_rhetoric_equations(expert_guidance, expert_analysis)
        print(f"ğŸ§® ØªÙƒÙŠÙ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ©: {len(equation_adaptations)} Ù…Ø¹Ø§Ø¯Ù„Ø©")

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ø§Ù„Ù…ØªÙƒÙŠÙ
        rhetoric_analysis = self._perform_adaptive_rhetoric_analysis(request, equation_adaptations)

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ù‚ÙŠØ§Ø³ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©
        performance_improvements = self._measure_rhetoric_improvements(request, rhetoric_analysis, equation_adaptations)

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø¤Ù‰ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
        learning_insights = self._extract_rhetoric_learning_insights(request, rhetoric_analysis, performance_improvements)

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 7: ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù„Ù„Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
        next_cycle_recommendations = self._generate_rhetoric_next_cycle_recommendations(performance_improvements, learning_insights)

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        result = RhetoricAnalysisResult(
            success=True,
            text=request.text,
            literary_style=rhetoric_analysis.get("literary_style", ""),
            rhetorical_devices=rhetoric_analysis.get("rhetorical_devices", []),
            eloquence_score=rhetoric_analysis.get("eloquence_score", 0.0),
            beauty_assessment=rhetoric_analysis.get("beauty_assessment", {}),
            rhythm_analysis=rhetoric_analysis.get("rhythm_analysis", {}),
            overall_rhetoric_quality=rhetoric_analysis.get("overall_rhetoric_quality", 0.0),
            expert_guidance_applied=expert_guidance.__dict__,
            equation_adaptations=equation_adaptations,
            performance_improvements=performance_improvements,
            learning_insights=learning_insights,
            next_cycle_recommendations=next_cycle_recommendations
        )

        # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
        self._save_rhetoric_learning(request, result)

        total_time = (datetime.now() - start_time).total_seconds()
        print(f"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ø§Ù„Ù…ÙˆØ¬Ù‡ ÙÙŠ {total_time:.2f} Ø«Ø§Ù†ÙŠØ©")

        return result

    def _analyze_rhetoric_request_with_expert(self, request: RhetoricAnalysisRequest) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø·Ù„Ø¨ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø®Ø¨ÙŠØ±"""

        # ØªØ­Ù„ÙŠÙ„ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù†Øµ
        words = request.text.split()
        text_complexity = len(words) * 1.2  # Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø£Ø¹Ù‚Ø¯ Ù…Ù† Ø§Ù„Ù†Ø­Ùˆ
        context_complexity = len(request.context.split()) * 0.6 if request.context else 0

        # ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        aspects = request.rhetoric_aspects or ["metaphor", "simile", "alliteration", "rhythm", "eloquence"]
        aspects_complexity = len(aspects) * 4.0  # Ø§Ù„Ø¨Ù„Ø§ØºØ© Ù…Ø¹Ù‚Ø¯Ø© Ø¬Ø¯Ø§Ù‹

        # ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        depth_complexity = {
            "basic": 4.0,
            "intermediate": 8.0,
            "comprehensive": 12.0
        }.get(request.analysis_depth, 8.0)

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ù„Ù„Ù†Øµ
        rhetorical_complexity = 0
        if any(word in request.text for word in ["ÙƒØ£Ù†", "Ù…Ø«Ù„", "Ø´Ø¨Ù‡", "ÙŠØ´Ø¨Ù‡"]):
            rhetorical_complexity += 4  # ØªØ´Ø¨ÙŠÙ‡
        if any(word in request.text for word in ["Ø§Ø³ØªØ¹Ø§Ø±", "ÙƒÙ†Ø§ÙŠØ©", "Ù…Ø¬Ø§Ø²"]):
            rhetorical_complexity += 5  # Ø§Ø³ØªØ¹Ø§Ø±Ø© Ø£Ùˆ ÙƒÙ†Ø§ÙŠØ©
        if len([word for word in words if len(word) > 6]) > len(words) * 0.3:
            rhetorical_complexity += 3  # Ø£Ù„ÙØ§Ø¸ Ù…Ø¹Ù‚Ø¯Ø©

        total_complexity = text_complexity + context_complexity + aspects_complexity + depth_complexity + rhetorical_complexity

        return {
            "text_complexity": text_complexity,
            "context_complexity": context_complexity,
            "aspects_complexity": aspects_complexity,
            "depth_complexity": depth_complexity,
            "rhetorical_complexity": rhetorical_complexity,
            "total_complexity": total_complexity,
            "complexity_assessment": "Ø¨Ù„Ø§ØºØ© Ù…Ø¹Ù‚Ø¯Ø© Ø¬Ø¯Ø§Ù‹" if total_complexity > 35 else "Ø¨Ù„Ø§ØºØ© Ù…ØªÙˆØ³Ø·Ø©" if total_complexity > 20 else "Ø¨Ù„Ø§ØºØ© Ø¨Ø³ÙŠØ·Ø©",
            "recommended_adaptations": int(total_complexity // 4) + 5,
            "focus_areas": self._identify_rhetoric_focus_areas(request)
        }

    def _identify_rhetoric_focus_areas(self, request: RhetoricAnalysisRequest) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø§Ù„Ø¨Ù„Ø§ØºÙŠ"""
        focus_areas = []

        aspects = request.rhetoric_aspects or ["metaphor", "simile", "alliteration", "rhythm", "eloquence"]

        if "metaphor" in aspects:
            focus_areas.append("metaphor_detection_enhancement")
        if "simile" in aspects:
            focus_areas.append("simile_recognition_improvement")
        if "alliteration" in aspects:
            focus_areas.append("alliteration_analysis_optimization")
        if "rhythm" in aspects:
            focus_areas.append("rhythm_detection_refinement")
        if "eloquence" in aspects:
            focus_areas.append("eloquence_measurement_enhancement")

        # ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù†Øµ
        words = request.text.split()
        if len(words) > 15:
            focus_areas.append("complex_text_handling")
        if any(word in request.text for word in ["ÙƒØ£Ù†", "Ù…Ø«Ù„", "Ø´Ø¨Ù‡"]):
            focus_areas.append("simile_processing")
        if any(word in request.text for word in ["Ø§Ø³ØªØ¹Ø§Ø±", "ÙƒÙ†Ø§ÙŠØ©"]):
            focus_areas.append("metaphor_processing")
        if len([word for word in words if word.endswith("Ø©") or word.endswith("Ø§Ù†")]) > 2:
            focus_areas.append("rhyme_analysis")
        if request.context:
            focus_areas.append("contextual_rhetoric_analysis")

        return focus_areas

    def _generate_rhetoric_expert_guidance(self, request: RhetoricAnalysisRequest, analysis: Dict[str, Any]):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ø§Ù„Ø®Ø¨ÙŠØ± Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ"""

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ù„Ù„Ø¨Ù„Ø§ØºØ©
        target_complexity = 20 + analysis["recommended_adaptations"]

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø°Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        priority_functions = []
        if "metaphor_detection_enhancement" in analysis["focus_areas"]:
            priority_functions.extend(["gaussian", "softplus"])  # Ù„ÙƒØ´Ù Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª
        if "simile_recognition_improvement" in analysis["focus_areas"]:
            priority_functions.extend(["sin_cos", "tanh"])  # Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª
        if "alliteration_analysis_optimization" in analysis["focus_areas"]:
            priority_functions.extend(["swish", "squared_relu"])  # Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø³
        if "rhythm_detection_refinement" in analysis["focus_areas"]:
            priority_functions.extend(["hyperbolic", "softsign"])  # Ù„ÙƒØ´Ù Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
        if "eloquence_measurement_enhancement" in analysis["focus_areas"]:
            priority_functions.extend(["sin", "cos"])  # Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„ÙØµØ§Ø­Ø©
        if "complex_text_handling" in analysis["focus_areas"]:
            priority_functions.extend(["gaussian", "softplus"])  # Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
        if "simile_processing" in analysis["focus_areas"]:
            priority_functions.extend(["tanh", "swish"])  # Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ´Ø¨ÙŠÙ‡
        if "metaphor_processing" in analysis["focus_areas"]:
            priority_functions.extend(["gaussian", "hyperbolic"])  # Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø©

        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
        if analysis["complexity_assessment"] == "Ø¨Ù„Ø§ØºØ© Ù…Ø¹Ù‚Ø¯Ø© Ø¬Ø¯Ø§Ù‹":
            recommended_evolution = "increase"
            adaptation_strength = 0.98
        elif analysis["complexity_assessment"] == "Ø¨Ù„Ø§ØºØ© Ù…ØªÙˆØ³Ø·Ø©":
            recommended_evolution = "restructure"
            adaptation_strength = 0.85
        else:
            recommended_evolution = "maintain"
            adaptation_strength = 0.75

        return MockRhetoricGuidance(
            target_complexity=target_complexity,
            focus_areas=analysis["focus_areas"],
            adaptation_strength=adaptation_strength,
            priority_functions=priority_functions or ["gaussian", "softplus"],
            recommended_evolution=recommended_evolution
        )

    def _adapt_rhetoric_equations(self, guidance, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙƒÙŠÙ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ©"""

        adaptations = {}

        # Ø¥Ù†Ø´Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ ÙˆÙ‡Ù…ÙŠ Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ©
        mock_analysis = MockRhetoricAnalysis(
            rhetoric_accuracy=0.4,
            metaphor_clarity=0.5,
            literary_coherence=0.45,
            eloquence_precision=0.35,
            areas_for_improvement=guidance.focus_areas
        )

        # ØªÙƒÙŠÙ ÙƒÙ„ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø¨Ù„Ø§ØºØ©
        for eq_name, equation in self.rhetoric_equations.items():
            print(f"   ğŸ¨ ØªÙƒÙŠÙ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø¨Ù„Ø§ØºØ©: {eq_name}")
            equation.adapt_with_expert_guidance(guidance, mock_analysis)
            adaptations[eq_name] = equation.get_expert_guidance_summary()

        return adaptations

    def _perform_adaptive_rhetoric_analysis(self, request: RhetoricAnalysisRequest, adaptations: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ø§Ù„Ù…ØªÙƒÙŠÙ"""

        analysis_results = {
            "literary_style": "",
            "rhetorical_devices": [],
            "eloquence_score": 0.0,
            "beauty_assessment": {},
            "rhythm_analysis": {},
            "overall_rhetoric_quality": 0.0
        }

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ø¯Ø¨ÙŠ
        literary_style = self._identify_literary_style_adaptive(request.text)
        analysis_results["literary_style"] = literary_style

        # ÙƒØ´Ù Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©
        metaphor_accuracy = adaptations.get("metaphor_detector", {}).get("metaphor_detection", 0.5)
        simile_accuracy = adaptations.get("simile_analyzer", {}).get("simile_recognition", 0.55)
        rhetorical_devices = self._detect_rhetorical_devices_adaptive(request.text, metaphor_accuracy, simile_accuracy)
        analysis_results["rhetorical_devices"] = rhetorical_devices

        # Ù‚ÙŠØ§Ø³ Ø§Ù„ÙØµØ§Ø­Ø©
        eloquence_accuracy = adaptations.get("eloquence_measurer", {}).get("eloquence_measurement", 0.35)
        eloquence_score = self._measure_eloquence_adaptive(request.text, eloquence_accuracy)
        analysis_results["eloquence_score"] = eloquence_score

        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ø§Ù„
        beauty_accuracy = adaptations.get("beauty_assessor", {}).get("literary_beauty_assessment", 0.3)
        beauty_assessment = self._assess_beauty_adaptive(request.text, rhetorical_devices, beauty_accuracy)
        analysis_results["beauty_assessment"] = beauty_assessment

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
        rhythm_accuracy = adaptations.get("rhythm_analyzer", {}).get("rhythm_detection", 0.4)
        rhythm_analysis = self._analyze_rhythm_adaptive(request.text, rhythm_accuracy)
        analysis_results["rhythm_analysis"] = rhythm_analysis

        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        overall_quality = np.mean([eloquence_score, beauty_assessment.get("overall_beauty", 0), rhythm_analysis.get("rhythm_quality", 0)])
        analysis_results["overall_rhetoric_quality"] = overall_quality

        return analysis_results

    def _identify_literary_style_adaptive(self, text: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ø¯Ø¨ÙŠ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ØªÙƒÙŠÙØ©"""

        words = text.split()

        # Ø£Ø³Ù„ÙˆØ¨ Ø¬Ø§Ù‡Ù„ÙŠ (Ù‚ÙˆØ© ÙˆØµØ¯Ù‚)
        if any(word in text for word in ["ØµØ­Ø±Ø§Ø¡", "Ù†Ø§Ù‚Ø©", "Ø³ÙŠÙ", "Ø´Ø¬Ø§Ø¹", "ÙƒØ±ÙŠÙ…"]):
            return "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¬Ø§Ù‡Ù„ÙŠ"

        # Ø£Ø³Ù„ÙˆØ¨ Ø¥Ø³Ù„Ø§Ù…ÙŠ (ÙˆØ¶ÙˆØ­ ÙˆØ¨Ø³Ø§Ø·Ø©)
        if any(word in text for word in ["Ø§Ù„Ù„Ù‡", "Ø±Ø³ÙˆÙ„", "Ø¥ÙŠÙ…Ø§Ù†", "ØªÙ‚ÙˆÙ‰", "Ø¬Ù†Ø©"]):
            return "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ"

        # Ø£Ø³Ù„ÙˆØ¨ Ø¹Ø¨Ø§Ø³ÙŠ (ØªØ¹Ù‚ÙŠØ¯ ÙˆØ²Ø®Ø±ÙØ©)
        if len([word for word in words if len(word) > 7]) > len(words) * 0.4:
            return "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠ"

        # Ø£Ø³Ù„ÙˆØ¨ Ø£Ù†Ø¯Ù„Ø³ÙŠ (Ø±Ù‚Ø© ÙˆØ·Ø¨ÙŠØ¹Ø©)
        if any(word in text for word in ["Ø­Ø¯ÙŠÙ‚Ø©", "Ù†Ù‡Ø±", "Ø²Ù‡Ø±", "Ø¹Ø·Ø±", "Ø¬Ù…Ø§Ù„"]):
            return "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ù†Ø¯Ù„Ø³ÙŠ"

        # Ø£Ø³Ù„ÙˆØ¨ Ø­Ø¯ÙŠØ« (Ø¨Ø³Ø§Ø·Ø© ÙˆØªØ¬Ø¯ÙŠØ¯)
        if len(words) < 20 and not any(word in text for word in ["ÙƒØ£Ù†", "Ù…Ø«Ù„", "Ø§Ø³ØªØ¹Ø§Ø±"]):
            return "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø­Ø¯ÙŠØ«"

        return "Ø£Ø³Ù„ÙˆØ¨ Ù…Ø®ØªÙ„Ø·"

    def _detect_rhetorical_devices_adaptive(self, text: str, metaphor_accuracy: float, simile_accuracy: float) -> List[RhetoricalDevice]:
        """ÙƒØ´Ù Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ØªÙƒÙŠÙØ©"""

        devices = []

        # ÙƒØ´Ù Ø§Ù„ØªØ´Ø¨ÙŠÙ‡
        simile_patterns = ["ÙƒØ£Ù†", "Ù…Ø«Ù„", "Ø´Ø¨Ù‡", "ÙŠØ´Ø¨Ù‡", "ÙƒØ§Ù„Ù€"]
        for pattern in simile_patterns:
            if pattern in text:
                device = RhetoricalDevice(
                    device_type="ØªØ´Ø¨ÙŠÙ‡",
                    text_span=f"Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ØªÙˆÙŠ Ø¹Ù„Ù‰ '{pattern}'",
                    description="ØªØ´Ø¨ÙŠÙ‡ ÙŠÙˆØ¶Ø­ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø¨Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©",
                    literary_effect="ØªÙˆØ¶ÙŠØ­ ÙˆØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¹Ù†Ù‰",
                    beauty_score=0.7,
                    confidence=simile_accuracy
                )
                devices.append(device)

        # ÙƒØ´Ù Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø© (ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ·)
        metaphor_indicators = ["ÙŠØ¶Ø­Ùƒ", "ÙŠØ¨ÙƒÙŠ", "ÙŠÙ†Ø§Ù…", "ÙŠØ³ØªÙŠÙ‚Ø¸"]
        for indicator in metaphor_indicators:
            if indicator in text and not any(word in text for word in ["Ø§Ù„Ø¥Ù†Ø³Ø§Ù†", "Ø§Ù„Ø±Ø¬Ù„", "Ø§Ù„Ù…Ø±Ø£Ø©"]):
                device = RhetoricalDevice(
                    device_type="Ø§Ø³ØªØ¹Ø§Ø±Ø©",
                    text_span=f"Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ØªÙˆÙŠ Ø¹Ù„Ù‰ '{indicator}'",
                    description="Ø§Ø³ØªØ¹Ø§Ø±Ø© ØªØ¶ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù…Ø§Ø¯",
                    literary_effect="ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¹Ù†Ù‰ ÙˆØ²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¬Ù…Ø§Ù„",
                    beauty_score=0.8,
                    confidence=metaphor_accuracy
                )
                devices.append(device)

        # ÙƒØ´Ù Ø§Ù„Ø¬Ù†Ø§Ø³ (ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£ØµÙˆØ§Øª)
        words = text.split()
        for i in range(len(words) - 1):
            if len(words[i]) > 3 and len(words[i+1]) > 3:
                if words[i][:3] == words[i+1][:3] or words[i][-3:] == words[i+1][-3:]:
                    device = RhetoricalDevice(
                        device_type="Ø¬Ù†Ø§Ø³",
                        text_span=f"{words[i]} - {words[i+1]}",
                        description="Ø¬Ù†Ø§Ø³ ÙŠØ­Ø¯Ø« Ø¬Ù…Ø§Ù„Ø§Ù‹ ØµÙˆØªÙŠØ§Ù‹",
                        literary_effect="Ø¥ÙŠÙ‚Ø§Ø¹ Ù…ÙˆØ³ÙŠÙ‚ÙŠ Ø¬Ù…ÙŠÙ„",
                        beauty_score=0.6,
                        confidence=0.6
                    )
                    devices.append(device)

        return devices

    def _measure_eloquence_adaptive(self, text: str, accuracy: float) -> float:
        """Ù‚ÙŠØ§Ø³ Ø§Ù„ÙØµØ§Ø­Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ØªÙƒÙŠÙØ©"""

        words = text.split()

        # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ÙØµØ§Ø­Ø©
        word_clarity = len([word for word in words if len(word) >= 3 and len(word) <= 8]) / len(words)
        meaning_clarity = 1.0 - (len([word for word in words if len(word) > 10]) / len(words))
        expression_beauty = len([word for word in words if word.endswith("Ø©") or word.endswith("Ø§Ù†")]) / len(words)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØµØ§Ø­Ø©
        eloquence = (word_clarity * 0.4 + meaning_clarity * 0.4 + expression_beauty * 0.2) * accuracy

        return min(1.0, eloquence)

    def _assess_beauty_adaptive(self, text: str, devices: List[RhetoricalDevice], accuracy: float) -> Dict[str, float]:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ø§Ù„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ØªÙƒÙŠÙØ©"""

        # Ø¬Ù…Ø§Ù„ Ø§Ù„Ø£Ù„ÙØ§Ø¸
        words = text.split()
        word_beauty = len([word for word in words if len(word) >= 4]) / len(words)

        # Ø¬Ù…Ø§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ
        meaning_beauty = len(devices) * 0.1  # ÙƒÙ„ Ø¬Ù‡Ø§Ø² Ø¨Ù„Ø§ØºÙŠ ÙŠØ²ÙŠØ¯ Ø§Ù„Ø¬Ù…Ø§Ù„

        # Ø¬Ù…Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
        rhythm_beauty = len([word for word in words if word.endswith("Ø©") or word.endswith("Ø§Ù†")]) / len(words)

        # Ø§Ù„Ø¬Ù…Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        overall_beauty = (word_beauty * 0.4 + meaning_beauty * 0.3 + rhythm_beauty * 0.3) * accuracy

        return {
            "word_beauty": min(1.0, word_beauty),
            "meaning_beauty": min(1.0, meaning_beauty),
            "rhythm_beauty": min(1.0, rhythm_beauty),
            "overall_beauty": min(1.0, overall_beauty)
        }

    def _analyze_rhythm_adaptive(self, text: str, accuracy: float) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ØªÙƒÙŠÙØ©"""

        words = text.split()

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§ÙÙŠØ©
        rhyme_endings = {}
        for word in words:
            if len(word) >= 3:
                ending = word[-2:]
                rhyme_endings[ending] = rhyme_endings.get(ending, 0) + 1

        # Ø£ÙƒØ«Ø± Ù‚Ø§ÙÙŠØ© ØªÙƒØ±Ø§Ø±Ø§Ù‹
        most_common_rhyme = max(rhyme_endings.values()) if rhyme_endings else 0
        rhyme_consistency = most_common_rhyme / len(words) if words else 0

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ²Ù† (ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ·)
        meter_pattern = self._detect_meter_pattern_simple(text)

        # Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
        rhythm_quality = (rhyme_consistency * 0.6 + (1 if meter_pattern != "ØºÙŠØ± Ù…Ø­Ø¯Ø¯" else 0) * 0.4) * accuracy

        return {
            "rhyme_consistency": rhyme_consistency,
            "meter_pattern": meter_pattern,
            "rhythm_quality": min(1.0, rhythm_quality),
            "musical_effect": "Ø¹Ø§Ù„ÙŠ" if rhythm_quality > 0.7 else "Ù…ØªÙˆØ³Ø·" if rhythm_quality > 0.4 else "Ø¶Ø¹ÙŠÙ"
        }

    def _detect_meter_pattern_simple(self, text: str) -> str:
        """ÙƒØ´Ù Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø´Ø¹Ø±ÙŠ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©"""

        words = text.split()

        # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ù„ÙˆØ²Ù† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        word_lengths = [len(word) for word in words]
        avg_length = np.mean(word_lengths) if word_lengths else 0

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ÙˆØ²Ù† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        if avg_length >= 6:
            return "Ø§Ù„Ø·ÙˆÙŠÙ„"
        elif avg_length >= 5:
            return "Ø§Ù„ÙƒØ§Ù…Ù„"
        elif avg_length >= 4:
            return "Ø§Ù„ÙˆØ§ÙØ±"
        elif avg_length >= 3:
            return "Ø§Ù„Ø¨Ø³ÙŠØ·"
        else:
            return "Ø§Ù„Ø±Ø¬Ø²"

    def _measure_rhetoric_improvements(self, request: RhetoricAnalysisRequest, analysis: Dict[str, Any], adaptations: Dict[str, Any]) -> Dict[str, float]:
        """Ù‚ÙŠØ§Ø³ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¨Ù„Ø§ØºØ©"""

        improvements = {}

        # ØªØ­Ø³Ù† Ø¯Ù‚Ø© Ø§Ù„Ø¨Ù„Ø§ØºØ©
        avg_rhetoric_accuracy = np.mean([adapt.get("rhetoric_accuracy", 0.4) for adapt in adaptations.values()])
        baseline_rhetoric_accuracy = 0.3
        rhetoric_accuracy_improvement = ((avg_rhetoric_accuracy - baseline_rhetoric_accuracy) / baseline_rhetoric_accuracy) * 100
        improvements["rhetoric_accuracy_improvement"] = max(0, rhetoric_accuracy_improvement)

        # ØªØ­Ø³Ù† ÙƒØ´Ù Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª
        avg_metaphor_detection = np.mean([adapt.get("metaphor_detection", 0.5) for adapt in adaptations.values()])
        baseline_metaphor_detection = 0.4
        metaphor_detection_improvement = ((avg_metaphor_detection - baseline_metaphor_detection) / baseline_metaphor_detection) * 100
        improvements["metaphor_detection_improvement"] = max(0, metaphor_detection_improvement)

        # ØªØ­Ø³Ù† ØªÙ…ÙŠÙŠØ² Ø§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª
        avg_simile_recognition = np.mean([adapt.get("simile_recognition", 0.55) for adapt in adaptations.values()])
        baseline_simile_recognition = 0.45
        simile_recognition_improvement = ((avg_simile_recognition - baseline_simile_recognition) / baseline_simile_recognition) * 100
        improvements["simile_recognition_improvement"] = max(0, simile_recognition_improvement)

        # ØªØ­Ø³Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø³
        avg_alliteration_analysis = np.mean([adapt.get("alliteration_analysis", 0.45) for adapt in adaptations.values()])
        baseline_alliteration_analysis = 0.35
        alliteration_analysis_improvement = ((avg_alliteration_analysis - baseline_alliteration_analysis) / baseline_alliteration_analysis) * 100
        improvements["alliteration_analysis_improvement"] = max(0, alliteration_analysis_improvement)

        # ØªØ­Ø³Ù† ÙƒØ´Ù Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
        avg_rhythm_detection = np.mean([adapt.get("rhythm_detection", 0.4) for adapt in adaptations.values()])
        baseline_rhythm_detection = 0.3
        rhythm_detection_improvement = ((avg_rhythm_detection - baseline_rhythm_detection) / baseline_rhythm_detection) * 100
        improvements["rhythm_detection_improvement"] = max(0, rhythm_detection_improvement)

        # ØªØ­Ø³Ù† Ù‚ÙŠØ§Ø³ Ø§Ù„ÙØµØ§Ø­Ø©
        avg_eloquence_measurement = np.mean([adapt.get("eloquence_measurement", 0.35) for adapt in adaptations.values()])
        baseline_eloquence_measurement = 0.25
        eloquence_measurement_improvement = ((avg_eloquence_measurement - baseline_eloquence_measurement) / baseline_eloquence_measurement) * 100
        improvements["eloquence_measurement_improvement"] = max(0, eloquence_measurement_improvement)

        # ØªØ­Ø³Ù† ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ø§Ù„
        avg_beauty_assessment = np.mean([adapt.get("literary_beauty_assessment", 0.3) for adapt in adaptations.values()])
        baseline_beauty_assessment = 0.2
        beauty_assessment_improvement = ((avg_beauty_assessment - baseline_beauty_assessment) / baseline_beauty_assessment) * 100
        improvements["beauty_assessment_improvement"] = max(0, beauty_assessment_improvement)

        # ØªØ­Ø³Ù† Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
        total_adaptations = sum(adapt.get("total_adaptations", 0) for adapt in adaptations.values())
        rhetoric_complexity_improvement = total_adaptations * 18  # ÙƒÙ„ ØªÙƒÙŠÙ Ø¨Ù„Ø§ØºÙŠ = 18% ØªØ­Ø³Ù†
        improvements["rhetoric_complexity_improvement"] = rhetoric_complexity_improvement

        return improvements

    def _extract_rhetoric_learning_insights(self, request: RhetoricAnalysisRequest, analysis: Dict[str, Any], improvements: Dict[str, float]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø¤Ù‰ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¨Ù„Ø§ØºÙŠ"""

        insights = []

        if improvements["rhetoric_accuracy_improvement"] > 30:
            insights.append("Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ± Ø­Ø³Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ø¨Ø´ÙƒÙ„ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ")

        if improvements["metaphor_detection_improvement"] > 25:
            insights.append("Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ù…ØªÙƒÙŠÙØ© Ù…Ù…ØªØ§Ø²Ø© Ù„ÙƒØ´Ù Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")

        if improvements["simile_recognition_improvement"] > 22:
            insights.append("Ø§Ù„Ù†Ø¸Ø§Ù… Ù†Ø¬Ø­ ÙÙŠ ØªØ­Ø³ÙŠÙ† ØªÙ…ÙŠÙŠØ² Ø§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©")

        if improvements["alliteration_analysis_improvement"] > 28:
            insights.append("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø³ ÙˆØ§Ù„Ø³Ø¬Ø¹ ØªØ­Ø³Ù† Ù…Ø¹ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø®Ø¨ÙŠØ±")

        if improvements["rhythm_detection_improvement"] > 33:
            insights.append("ÙƒØ´Ù Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ ÙˆØ§Ù„ÙˆØ²Ù† Ø£ØµØ¨Ø­ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© Ù…Ø¹ Ø§Ù„ØªÙƒÙŠÙ")

        if improvements["eloquence_measurement_improvement"] > 40:
            insights.append("Ù‚ÙŠØ§Ø³ Ø§Ù„ÙØµØ§Ø­Ø© ØªØ­Ø³Ù† Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸ Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ù…ØªÙƒÙŠÙØ©")

        if improvements["beauty_assessment_improvement"] > 50:
            insights.append("ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ø§Ù„ Ø§Ù„Ø£Ø¯Ø¨ÙŠ ÙˆØµÙ„ Ù„Ù…Ø³ØªÙˆÙ‰ Ù…ØªÙ‚Ø¯Ù…")

        if improvements["rhetoric_complexity_improvement"] > 150:
            insights.append("Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ© Ø§Ù„Ù…ØªÙƒÙŠÙØ© ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠ Ø¨Ø¥ØªÙ‚Ø§Ù†")

        # Ø±Ø¤Ù‰ Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù†Øµ
        words_count = len(request.text.split())
        if words_count > 15:
            insights.append("Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØªØ¹Ø§Ù…Ù„ Ø¨ÙƒÙØ§Ø¡Ø© Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©")

        if request.context:
            insights.append("Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ ÙŠØ­Ø³Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ")

        if analysis.get("literary_style") in ["Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¬Ø§Ù‡Ù„ÙŠ", "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø¨Ø§Ø³ÙŠ"]:
            insights.append("Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù„Ù„ Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠØ© Ø¨Ø¯Ù‚Ø© Ù…ØªÙ‚Ø¯Ù…Ø©")

        if len(analysis.get("rhetorical_devices", [])) > 2:
            insights.append("Ø§Ù„Ù†Ø¸Ø§Ù… ÙƒØ´Ù Ø£Ø¬Ù‡Ø²Ø© Ø¨Ù„Ø§ØºÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø© ÙÙŠ Ø§Ù„Ù†Øµ")

        return insights

    def _generate_rhetoric_next_cycle_recommendations(self, improvements: Dict[str, float], insights: List[str]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù„Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©"""

        recommendations = []

        avg_improvement = np.mean(list(improvements.values()))

        if avg_improvement > 45:
            recommendations.append("Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠØ©")
            recommendations.append("ØªØ¬Ø±Ø¨Ø© ØªØ­Ù„ÙŠÙ„ Ø¨Ù„Ø§ØºÙŠ Ø£Ø¹Ù…Ù‚ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø´Ø¹Ø±ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©")
        elif avg_improvement > 25:
            recommendations.append("Ø²ÙŠØ§Ø¯Ø© Ù‚ÙˆØ© Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹")
            recommendations.append("Ø¥Ø¶Ø§ÙØ© Ø£Ø¬Ù‡Ø²Ø© Ø¨Ù„Ø§ØºÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©")
        else:
            recommendations.append("Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ")
            recommendations.append("ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø¨Ù„Ø§ØºØ©")

        # ØªÙˆØµÙŠØ§Øª Ù…Ø­Ø¯Ø¯Ø©
        if "Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª" in str(insights):
            recommendations.append("Ø§Ù„ØªÙˆØ³Ø¹ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")

        if "Ø§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª" in str(insights):
            recommendations.append("ØªØ·ÙˆÙŠØ± Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª ØªÙ…ÙŠÙŠØ² Ø§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©")

        if "Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹" in str(insights):
            recommendations.append("ØªØ­Ø³ÙŠÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø´Ø¹Ø±ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")

        if "Ø§Ù„ÙØµØ§Ø­Ø©" in str(insights):
            recommendations.append("ØªØ¹Ø²ÙŠØ² Ù…Ø¹Ø§ÙŠÙŠØ± Ù‚ÙŠØ§Ø³ Ø§Ù„ÙØµØ§Ø­Ø© ÙˆØ§Ù„Ø¨Ù„Ø§ØºØ©")

        if "Ø§Ù„Ø¬Ù…Ø§Ù„" in str(insights):
            recommendations.append("ØªØ·ÙˆÙŠØ± ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ø§Ù„ Ø§Ù„Ø£Ø¯Ø¨ÙŠ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯")

        if "Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠØ©" in str(insights):
            recommendations.append("Ø¥Ø¶Ø§ÙØ© ØªØ­Ù„ÙŠÙ„ Ù…ØªØ®ØµØµ Ù„Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© Ø§Ù„ØªØ±Ø§Ø«ÙŠØ©")

        return recommendations

    def _save_rhetoric_learning(self, request: RhetoricAnalysisRequest, result: RhetoricAnalysisResult):
        """Ø­ÙØ¸ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¨Ù„Ø§ØºÙŠ"""

        learning_entry = {
            "timestamp": datetime.now().isoformat(),
            "text": request.text,
            "context": request.context,
            "analysis_depth": request.analysis_depth,
            "success": result.success,
            "literary_style": result.literary_style,
            "eloquence_score": result.eloquence_score,
            "overall_rhetoric_quality": result.overall_rhetoric_quality,
            "rhetorical_devices_count": len(result.rhetorical_devices),
            "performance_improvements": result.performance_improvements,
            "learning_insights": result.learning_insights
        }

        text_key = f"{len(request.text.split())}_{request.analysis_depth}"
        if text_key not in self.rhetoric_learning_database:
            self.rhetoric_learning_database[text_key] = []

        self.rhetoric_learning_database[text_key].append(learning_entry)

        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 3 Ø¥Ø¯Ø®Ø§Ù„Ø§Øª ÙÙ‚Ø·
        if len(self.rhetoric_learning_database[text_key]) > 3:
            self.rhetoric_learning_database[text_key] = self.rhetoric_learning_database[text_key][-3:]

def main():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ±"""
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ø§Ù„Ø®Ø¨ÙŠØ±...")

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
    rhetoric_analyzer = ExpertGuidedArabicRhetoricAnalyzer()

    # Ù†ØµÙˆØµ Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù„Ø§ØºÙŠØ©
    test_texts = [
        "Ø§Ù„Ø¨Ø­Ø± ÙŠØ¶Ø­Ùƒ ÙˆØ§Ù„Ø£Ù…ÙˆØ§Ø¬ ØªÙ„Ø¹Ø¨ ÙƒØ§Ù„Ø£Ø·ÙØ§Ù„",
        "Ø§Ù„Ù„ÙŠÙ„ ÙƒØ£Ù†Ù‡ Ø¹Ø¨Ø§Ø¡Ø© Ø³ÙˆØ¯Ø§Ø¡ ØªØºØ·ÙŠ Ø§Ù„Ø£Ø±Ø¶",
        "ÙÙŠ Ø§Ù„ØµÙŠÙ Ø¶ÙŠÙ ÙˆØ§Ù„Ø´ØªØ§Ø¡ Ø´ØªØ§Øª",
        "Ø§Ù„Ù„Ù‡ Ù†ÙˆØ± Ø§Ù„Ø³Ù…Ø§ÙˆØ§Øª ÙˆØ§Ù„Ø£Ø±Ø¶",
        "Ø§Ù„Ø­Ø¯ÙŠÙ‚Ø© ØªÙÙˆØ­ Ø¨Ø¹Ø·Ø± Ø§Ù„Ø²Ù‡ÙˆØ± ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ ÙŠÙ…Ù„Ø£ Ø§Ù„Ù…ÙƒØ§Ù†"
    ]

    for text in test_texts:
        print(f"\n{'='*70}")
        print(f"ğŸ¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: {text}")

        # Ø·Ù„Ø¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
        rhetoric_request = RhetoricAnalysisRequest(
            text=text,
            context="Ø³ÙŠØ§Ù‚ Ø£Ø¯Ø¨ÙŠ ØªØ¬Ø±ÙŠØ¨ÙŠ",
            analysis_depth="comprehensive",
            rhetoric_aspects=["metaphor", "simile", "alliteration", "rhythm", "eloquence"],
            expert_guidance_level="adaptive",
            learning_enabled=True
        )

        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ
        rhetoric_result = rhetoric_analyzer.analyze_rhetoric_with_expert_guidance(rhetoric_request)

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©
        print(f"\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù„Ø§ØºÙŠ:")
        print(f"   âœ… Ø§Ù„Ù†Ø¬Ø§Ø­: {rhetoric_result.success}")
        print(f"   ğŸ“œ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø£Ø¯Ø¨ÙŠ: {rhetoric_result.literary_style}")
        print(f"   ğŸ¯ Ø¯Ø±Ø¬Ø© Ø§Ù„ÙØµØ§Ø­Ø©: {rhetoric_result.eloquence_score:.2%}")
        print(f"   â­ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©: {rhetoric_result.overall_rhetoric_quality:.2%}")

        if rhetoric_result.rhetorical_devices:
            print(f"   ğŸ¨ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø¨Ù„Ø§ØºÙŠØ©:")
            for device in rhetoric_result.rhetorical_devices:
                print(f"      â€¢ {device.device_type}: {device.text_span}")
                print(f"        Ø§Ù„ØªØ£Ø«ÙŠØ±: {device.literary_effect}")
                print(f"        Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬Ù…Ø§Ù„: {device.beauty_score:.1f}")

        if rhetoric_result.beauty_assessment:
            print(f"   ğŸ’ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ø§Ù„:")
            beauty = rhetoric_result.beauty_assessment
            print(f"      Ø¬Ù…Ø§Ù„ Ø§Ù„Ø£Ù„ÙØ§Ø¸: {beauty.get('word_beauty', 0):.2%}")
            print(f"      Ø¬Ù…Ø§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ: {beauty.get('meaning_beauty', 0):.2%}")
            print(f"      Ø¬Ù…Ø§Ù„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹: {beauty.get('rhythm_beauty', 0):.2%}")

        if rhetoric_result.rhythm_analysis:
            print(f"   ğŸµ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹:")
            rhythm = rhetoric_result.rhythm_analysis
            print(f"      Ø§Ù„ÙˆØ²Ù†: {rhythm.get('meter_pattern', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
            print(f"      Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚ÙŠ: {rhythm.get('musical_effect', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")

        if rhetoric_result.performance_improvements:
            print(f"   ğŸ“ˆ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡:")
            for metric, improvement in rhetoric_result.performance_improvements.items():
                print(f"      {metric}: {improvement:.1f}%")

        if rhetoric_result.learning_insights:
            print(f"   ğŸ§  Ø±Ø¤Ù‰ Ø§Ù„ØªØ¹Ù„Ù…:")
            for insight in rhetoric_result.learning_insights:
                print(f"      â€¢ {insight}")

if __name__ == "__main__":
    main()
