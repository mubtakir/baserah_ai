#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÙØ§Ø­Øµ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© - Traditional Elements Scanner
ÙŠÙØ­Øµ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø£ÙŠ Ø¹Ù†Ø§ØµØ± ØªÙ‚Ù„ÙŠØ¯ÙŠØ© Ù…Ø®ÙÙŠØ©

Author: Basil Yahya Abdullah - Iraq/Mosul
"""

import os
import re
from typing import Dict, List, Set, Tuple
from pathlib import Path


class TraditionalElementsScanner:
    """ÙØ§Ø­Øµ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙØ§Ø­Øµ"""
        # Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
        self.forbidden_imports = {
            'torch', 'torch.nn', 'torch.optim', 'torch.nn.functional',
            'tensorflow', 'tf', 'keras', 'sklearn', 'scikit-learn',
            'pytorch', 'theano', 'caffe', 'mxnet', 'paddle',
            'gym', 'stable_baselines', 'ray', 'rllib'
        }
        
        self.forbidden_classes = {
            'nn.Module', 'nn.Linear', 'nn.Conv2d', 'nn.LSTM', 'nn.GRU',
            'nn.Sequential', 'nn.ReLU', 'nn.Sigmoid', 'nn.Tanh',
            'optim.Adam', 'optim.SGD', 'optim.RMSprop',
            'F.relu', 'F.sigmoid', 'F.softmax', 'F.mse_loss',
            'Model', 'Sequential', 'Dense', 'Conv2D', 'LSTM'
        }
        
        self.forbidden_concepts = {
            'neural_network', 'deep_learning', 'machine_learning',
            'reinforcement_learning', 'gradient_descent', 'backpropagation',
            'loss_function', 'optimizer', 'learning_rate', 'batch_size',
            'epoch', 'training', 'validation', 'test_set',
            'overfitting', 'underfitting', 'regularization',
            'dropout', 'batch_norm', 'activation_function'
        }
        
        self.forbidden_variables = {
            'learning_rate', 'lr', 'batch_size', 'epochs', 'loss',
            'optimizer', 'model', 'network', 'layers', 'weights',
            'biases', 'gradients', 'train_loader', 'test_loader',
            'accuracy', 'precision', 'recall', 'f1_score'
        }
        
        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self.scan_results = {
            'forbidden_imports': [],
            'forbidden_classes': [],
            'forbidden_concepts': [],
            'forbidden_variables': [],
            'suspicious_patterns': [],
            'clean_files': [],
            'problematic_files': []
        }
    
    def scan_file(self, file_path: str) -> Dict[str, List[str]]:
        """ÙØ­Øµ Ù…Ù„Ù ÙˆØ§Ø­Ø¯"""
        file_issues = {
            'forbidden_imports': [],
            'forbidden_classes': [],
            'forbidden_concepts': [],
            'forbidden_variables': [],
            'suspicious_patterns': []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            # ÙØ­Øµ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
            for line_num, line in enumerate(lines, 1):
                line_lower = line.lower().strip()
                
                # ÙØ­Øµ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
                if line_lower.startswith('import ') or line_lower.startswith('from '):
                    for forbidden in self.forbidden_imports:
                        if forbidden in line_lower:
                            file_issues['forbidden_imports'].append(
                                f"Line {line_num}: {line.strip()}"
                            )
                
                # ÙØ­Øµ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
                for forbidden in self.forbidden_classes:
                    if forbidden in line:
                        file_issues['forbidden_classes'].append(
                            f"Line {line_num}: {line.strip()}"
                        )
                
                # ÙØ­Øµ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
                for forbidden in self.forbidden_concepts:
                    if forbidden in line_lower:
                        file_issues['forbidden_concepts'].append(
                            f"Line {line_num}: {line.strip()}"
                        )
                
                # ÙØ­Øµ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
                for forbidden in self.forbidden_variables:
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØªØºÙŠØ± ÙƒØ§Ø³Ù… Ù…Ù†ÙØµÙ„
                    pattern = r'\b' + re.escape(forbidden) + r'\b'
                    if re.search(pattern, line_lower):
                        file_issues['forbidden_variables'].append(
                            f"Line {line_num}: {line.strip()}"
                        )
                
                # ÙØ­Øµ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©
                suspicious_patterns = [
                    r'\.backward\(\)', r'\.zero_grad\(\)', r'\.step\(\)',
                    r'\.train\(\)', r'\.eval\(\)', r'\.cuda\(\)',
                    r'torch\.', r'nn\.', r'F\.', r'optim\.',
                    r'loss\.', r'model\.', r'network\.'
                ]
                
                for pattern in suspicious_patterns:
                    if re.search(pattern, line):
                        file_issues['suspicious_patterns'].append(
                            f"Line {line_num}: {line.strip()}"
                        )
        
        except Exception as e:
            file_issues['suspicious_patterns'].append(f"Error reading file: {e}")
        
        return file_issues
    
    def scan_directory(self, directory_path: str) -> Dict[str, Any]:
        """ÙØ­Øµ Ù…Ø¬Ù„Ø¯ ÙƒØ§Ù…Ù„"""
        print(f"ğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯: {directory_path}")
        
        python_files = []
        for root, dirs, files in os.walk(directory_path):
            # ØªØ¬Ø§Ù‡Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø¹ÙŠÙ†Ø©
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            
            for file in files:
                if file.endswith('.py'):
                    python_files.append(os.path.join(root, file))
        
        print(f"ğŸ“ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(python_files)} Ù…Ù„Ù Python")
        
        # ÙØ­Øµ ÙƒÙ„ Ù…Ù„Ù
        for file_path in python_files:
            print(f"   ğŸ” ÙØ­Øµ: {os.path.basename(file_path)}")
            file_issues = self.scan_file(file_path)
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            has_issues = any(file_issues.values())
            
            if has_issues:
                self.scan_results['problematic_files'].append({
                    'file_path': file_path,
                    'issues': file_issues
                })
                
                # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¹Ø§Ù…Ø©
                self.scan_results['forbidden_imports'].extend(
                    [f"{file_path}: {issue}" for issue in file_issues['forbidden_imports']]
                )
                self.scan_results['forbidden_classes'].extend(
                    [f"{file_path}: {issue}" for issue in file_issues['forbidden_classes']]
                )
                self.scan_results['forbidden_concepts'].extend(
                    [f"{file_path}: {issue}" for issue in file_issues['forbidden_concepts']]
                )
                self.scan_results['forbidden_variables'].extend(
                    [f"{file_path}: {issue}" for issue in file_issues['forbidden_variables']]
                )
                self.scan_results['suspicious_patterns'].extend(
                    [f"{file_path}: {issue}" for issue in file_issues['suspicious_patterns']]
                )
            else:
                self.scan_results['clean_files'].append(file_path)
        
        return self.scan_results
    
    def generate_report(self) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        report = []
        report.append("ğŸŒŸ" + "="*80 + "ğŸŒŸ")
        report.append("ğŸ” ØªÙ‚Ø±ÙŠØ± ÙØ­Øµ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…")
        report.append("ğŸŒŸ" + "="*80 + "ğŸŒŸ")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        total_files = len(self.scan_results['clean_files']) + len(self.scan_results['problematic_files'])
        clean_files = len(self.scan_results['clean_files'])
        problematic_files = len(self.scan_results['problematic_files'])
        
        report.append(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©:")
        report.append(f"   ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙØ­ÙˆØµØ©: {total_files}")
        report.append(f"   âœ… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø¸ÙŠÙØ©: {clean_files}")
        report.append(f"   âš ï¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§: {problematic_files}")
        report.append(f"   ğŸ¯ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¸Ø§ÙØ©: {(clean_files/total_files)*100:.1f}%")
        
        # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
        if self.scan_results['forbidden_imports']:
            report.append(f"\nâŒ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø© ({len(self.scan_results['forbidden_imports'])}):")
            for issue in self.scan_results['forbidden_imports'][:10]:  # Ø£ÙˆÙ„ 10 ÙÙ‚Ø·
                report.append(f"   {issue}")
            if len(self.scan_results['forbidden_imports']) > 10:
                report.append(f"   ... Ùˆ {len(self.scan_results['forbidden_imports']) - 10} Ø£Ø®Ø±Ù‰")
        
        if self.scan_results['forbidden_classes']:
            report.append(f"\nâŒ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø© ({len(self.scan_results['forbidden_classes'])}):")
            for issue in self.scan_results['forbidden_classes'][:10]:
                report.append(f"   {issue}")
            if len(self.scan_results['forbidden_classes']) > 10:
                report.append(f"   ... Ùˆ {len(self.scan_results['forbidden_classes']) - 10} Ø£Ø®Ø±Ù‰")
        
        if self.scan_results['forbidden_concepts']:
            report.append(f"\nâŒ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø© ({len(self.scan_results['forbidden_concepts'])}):")
            for issue in self.scan_results['forbidden_concepts'][:10]:
                report.append(f"   {issue}")
            if len(self.scan_results['forbidden_concepts']) > 10:
                report.append(f"   ... Ùˆ {len(self.scan_results['forbidden_concepts']) - 10} Ø£Ø®Ø±Ù‰")
        
        if self.scan_results['suspicious_patterns']:
            report.append(f"\nâš ï¸ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø© ({len(self.scan_results['suspicious_patterns'])}):")
            for issue in self.scan_results['suspicious_patterns'][:10]:
                report.append(f"   {issue}")
            if len(self.scan_results['suspicious_patterns']) > 10:
                report.append(f"   ... Ùˆ {len(self.scan_results['suspicious_patterns']) - 10} Ø£Ø®Ø±Ù‰")
        
        # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§
        if self.scan_results['problematic_files']:
            report.append(f"\nğŸš¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø¥ØµÙ„Ø§Ø­:")
            for file_info in self.scan_results['problematic_files'][:20]:
                file_path = file_info['file_path']
                issues_count = sum(len(issues) for issues in file_info['issues'].values())
                report.append(f"   ğŸ“„ {os.path.basename(file_path)}: {issues_count} Ù…Ø´ÙƒÙ„Ø©")
        
        # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        report.append(f"\nğŸ† Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
        if problematic_files == 0:
            report.append("   ğŸ‰ Ù…Ù…ØªØ§Ø²! Ø§Ù„Ù†Ø¸Ø§Ù… Ø®Ø§Ù„Ù ØªÙ…Ø§Ù…Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©!")
        elif problematic_files <= total_files * 0.1:
            report.append("   âœ… Ø¬ÙŠØ¯! Ù…Ø¹Ø¸Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ù†Ø¸ÙŠÙ Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©")
        elif problematic_files <= total_files * 0.3:
            report.append("   âš ï¸ Ù…Ù‚Ø¨ÙˆÙ„! ÙŠØ­ØªØ§Ø¬ Ø¨Ø¹Ø¶ Ø§Ù„ØªÙ†Ø¸ÙŠÙ")
        else:
            report.append("   âŒ ÙŠØ­ØªØ§Ø¬ Ø¹Ù…Ù„! Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        return "\n".join(report)
    
    def save_report(self, output_file: str):
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù…Ù„Ù"""
        report = self.generate_report()
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {output_file}")


def scan_baserah_system():
    """ÙØ­Øµ Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„"""
    scanner = TraditionalElementsScanner()
    
    # ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    directories_to_scan = [
        'baserah_system/learning',
        'baserah_system/mathematical_core',
        'baserah_system/revolutionary_core',
        'baserah_system/adaptive_mathematical_core',
        'baserah_system/symbolic_processing'
    ]
    
    print("ğŸŒŸ" + "="*80 + "ğŸŒŸ")
    print("ğŸ” Ø¨Ø¯Ø¡ ÙØ­Øµ Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø© Ù„Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©")
    print("ğŸŒŸ" + "="*80 + "ğŸŒŸ")
    
    for directory in directories_to_scan:
        if os.path.exists(directory):
            scanner.scan_directory(directory)
        else:
            print(f"âš ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {directory}")
    
    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report = scanner.generate_report()
    print(report)
    
    scanner.save_report('traditional_elements_scan_report.txt')
    
    return scanner.scan_results


if __name__ == "__main__":
    scan_results = scan_baserah_system()
